{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: MNIST dataset using TPOT\n",
    "\n",
    "This is my initial foray into Jupyter Notebooks, data science in Python, and machine learning. I'll be keeping detailed notes on my exploration.\n",
    "\n",
    "I will be using TPOT to train a model on the MNIST dataset. The MNIST dataset consists of hand written digit, 0-9, and their associated labels. We're teaching the model to identify these hand written digits.\n",
    "\n",
    "TPOT is an automated machine learning tool. With this tool, you set a few parameters, point it at your data, and it comes up with an optomized machine learning pipeline for your data. The idea is that we can start to play with machine learning concepts and tools without having to worry too much about the technical details of picking and optimizing a model.\n",
    "\n",
    "We'll be following the basic example in TPOT's docs just to get an initial feel then playing around with the params and data.\n",
    "\n",
    "[TPOT GitHub](https://github.com/EpistasisLab/tpot)\n",
    "[TPOT Docs](http://epistasislab.github.io/tpot/)\n",
    "\n",
    "If you want to run this code yourself and are starting from scratch, here's how to get your environment setup for this notebook:\n",
    "\n",
    "[Install Anaconda](https://www.anaconda.com/download/)\n",
    "\n",
    "The tpot installation commands:\n",
    "\n",
    "> conda install numpy scipy scikit-learn pandas\n",
    "\n",
    "> pip install update_checker tqdm stopit\n",
    "\n",
    "TPOT's official docs just say to install deap. I had to run this:\n",
    "\n",
    "> pip install deap==1.0.2.post2\n",
    "\n",
    "> pip install tpot\n",
    "\n",
    "\n",
    "Open up this notebook with:\n",
    "> jupyter notebook mnist-tpot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's figure out TPOT\n",
    "\n",
    "#### Import your modules:\n",
    "\n",
    "You're familiar with TPOT, but we're also importing sklean here. Scikit Learn is the real workhorse here. It has the built in machine learning algorithms and tools that underlie TPOT. \n",
    "\n",
    "Note that we're cheating a bit (ok...alot) on the dataset here. Scikit Lean has built in sample data sets. These happen to include MNIST, so we're just loading that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPOTClassifier is what will be doing the bulk of our ML work for us.\n",
    "from tpot import TPOTClassifier\n",
    "# This is the sample MNIST dataset included with sklearn.\n",
    "from sklearn.datasets import load_digits\n",
    "# We discuss the use of train_test_split in the next section.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your data:\n",
    "\n",
    "In the next step we're loading the data then splitting into 4 sections. Understanding these splits is fundamental to understanding machine learning.\n",
    "\n",
    "Machine learning is really just about finding patterns in our data. But it's possible that we do too good of a job at finding patterns or find patterns that aren't really what we want. This is called overfitting.\n",
    "\n",
    "Imagine you want a model that classifies pictures of vehicles as either cars or trucks. Your model figures out that the pictures of trucks all have trees in the background and the cars don't, so that's how your model decides to detect 'car' vs 'truck'.  The problem here is that your model learned how to answer your question based on your data, but it doesn't really know how to detect what a car is.\n",
    "\n",
    "That previous example is probably a little too simple. A real ML algorithm tends to detect patterns in ways that we can't predict and aren't as clear cut as seeing trees. \n",
    "\n",
    "[Here's Google's in-depth explanation of overfitting, if you're interested](https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting)\n",
    "\n",
    "How do we know if we've overfit?\n",
    "\n",
    "We need training data to actually train the model and test data to make sure that we didn't just exactly learn the training data. Holding some data out for testing and validation purposes helps us prove that we didn't just overfit our model to our training data. We're using 75% of the data for training and 25% for testing.\n",
    "\n",
    "That's our first split.\n",
    "\n",
    "All of that data is then subdivided into the data (the picture. 'X' in this case) and the target (the label for the picture. Or 'y'). This is so we can tell the traning algorithm what it's trying to predict.\n",
    "\n",
    "That's our second split.\n",
    "\n",
    "Side note: We aren't actually 'looking at' pictures here. Each column in this dataset is a number representing the intensity of a pixel in the picture. Our model doesn't care what the picture literally looks like to a human. It just needs to be able to figure out a pattern in the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "digits = load_digits()\n",
    "# This is where we actually get our 4 way split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actaully creating a machine learning pipeline:\n",
    "\n",
    "This is the training example given in the TPOT docs for training. It scores a 98%, as advertised (98.66% to be exact).\n",
    "\n",
    "Let's break down what's happening here.\n",
    "\n",
    "1. TPOT has a Classifier and a Regressor class. Regressors guess a value. The classic example of this is guessing the price of a house. Classifiers are used to guess among distinct classes. The obvious example here being one of ten (0-9) possible digits. We're using TPOTClassifier. TPOT is using genetic programming to find an optimized machine learning pipeline for your data. The basics here are that TPOT trains a population (20 in our case), determines the best scoring models, then uses that information to inform what models are tested in the next generation (we're using 5 generations). The \"verbosity=2\" just gives us the nice little progress bars and updates on accuracy over the generations.\n",
    "\n",
    "2. \"tpot.fit(X_train, y_train)\" is just the equivalent of saying \"Go train. Use the training data\".\n",
    "\n",
    "3. \"tpot.score(X_test, y_test)\" is where we get to see how our model actually did. We'll get printouts of how each generation did, but this is where we actually get to see how the model works on new data.\n",
    "\n",
    "4. We save out generated pipeline to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "Generation 1 - Current best internal CV score: 0.962925749821777\n",
      "Generation 2 - Current best internal CV score: 0.9644405945378646\n",
      "Generation 3 - Current best internal CV score: 0.9666600833994199\n",
      "Generation 4 - Current best internal CV score: 0.9666600833994199\n",
      "Generation 5 - Current best internal CV score: 0.9858739654641543\n",
      "\n",
      "Best pipeline: LogisticRegression(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), C=10.0, dual=True, penalty=l2)\n",
      "0.9866666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_mnist_pipeline_v1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok...what did we just do?\n",
    "\n",
    "Each generation (ever 20 pipelines) outputs the accuracy score of the top performing ML pipeline so far. So our first generation had a top performer of 96.29% and we finished out at 98.58%. \n",
    "\n",
    "Here's the really important part: Those number are only for the training data.\n",
    "\n",
    "We don't see how our model performs on the test data until the end (the `tpot.score(X_test, y_test)`). This statement prints out the top performing pipeline, runs it with the testing data, and prints your final score. This is data that your model hasn't seen yet. This is the real deal.\n",
    "\n",
    "Our model performs at 98.66% on the testing data. \n",
    "\n",
    "TPOT creates a nice little ML pipeline file at the end so that you can reproduce these results, but let's ignore that for now.\n",
    "\n",
    "\n",
    "# Let's do it big\n",
    "\n",
    "Before we actually go in depth, let's just do it big by:\n",
    "- Running it longer by upping our generations and population_size\n",
    "- Using more cores by setting n_jobs=3 (use 3 CPU cores instead of 1).\n",
    "- Saving our progress to a folder by using periodic_checkpoint_folder (just in case my Windows desktop decides it wants to reboot in the night)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9851344299283016\n",
      "Generation 5 - Current best internal CV score: 0.9873535711606\n",
      "Generation 8 - Current best internal CV score: 0.9873671385770925\n",
      "Generation 9 - Current best internal CV score: 0.9888708984478656\n",
      "Generation 13 - Current best internal CV score: 0.9895980512222403\n",
      "Generation 16 - Current best internal CV score: 0.9896031703143171\n",
      "Generation 17 - Current best internal CV score: 0.991096262627164\n",
      "Generation 25 - Current best internal CV score: 0.9910990368600888\n",
      "Generation 26 - Current best internal CV score: 0.991828963867388\n",
      "Generation 27 - Current best internal CV score: 0.9918425312838807\n",
      "Generation 29 - Current best internal CV score: 0.992547668317347\n",
      "Generation 32 - Current best internal CV score: 0.9925724582911798\n",
      "Generation 43 - Current best internal CV score: 0.9932996110655544\n",
      "Generation 91 - Current best internal CV score: 0.9933131784820471\n",
      "Generation 162 - Current best internal CV score: 0.9933159527149715\n",
      "Generation 269 - Current best internal CV score: 0.9940458797222709\n",
      "Generation 344 - Current best internal CV score: 0.9940458797222709\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: KNeighborsClassifier(RandomForestClassifier(LogisticRegression(GradientBoostingClassifier(RFE(input_matrix, criterion=entropy, max_features=0.55, n_estimators=100, step=0.15000000000000002), learning_rate=1.0, max_depth=1, max_features=0.8500000000000001, min_samples_leaf=6, min_samples_split=5, n_estimators=100, subsample=0.25), C=1.0, dual=False, penalty=l1), bootstrap=False, criterion=gini, max_features=0.7500000000000001, min_samples_leaf=14, min_samples_split=14, n_estimators=100), n_neighbors=2, p=2, weights=distance)\n",
      "0.9844444444444445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=50000, population_size=200, n_jobs=3,\n",
    "                      periodic_checkpoint_folder='./mnist-tpot-checkpoint-2', verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_mnist_pipeline_v2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok...too big\n",
    "\n",
    "My assumpiton with my last pipeline was that it might run for a week. At 60 hours of training it was only 1% done. This would've taken months. Time to Ctrl+C and lick my wounds.\n",
    "\n",
    "If I was doing this over again I would've set these parameters:\n",
    "\n",
    "* max_time_mins=4320\n",
    "* early_stop=150\n",
    "* \\[REMOVE\\]generations=50000\n",
    "\n",
    "The \"max_time_mins\" is the amount of time you'll allow the pipeline to run. This variable overrides generations. I would've gone with 3 days (4,320 minutes).\n",
    "\n",
    "The \"early_stop\" variable will stop TPOT if there is no improvement over the specified number of generations. This number is honeslty fairly random. Our final jumps were coming at (very roughly) every 100 generations. 150 feels like a nice, safe buffer.\n",
    "\n",
    "#### So, how'd we do?\n",
    "\n",
    "I've cut out all of the repeat generations so that you can get a better idea of the pipeline at a glance.\n",
    "\n",
    "Remember when I talked about why we seperate out some test data? This training exercise is an example of why. Let's recap:\n",
    "\n",
    "|Run Num | Training Accuracy | Testing Accuracy|\n",
    "|--------|-------------------|-----------------|\n",
    "|1       |98.59%             |98.66%           |\n",
    "|2       |99.40%             |98.44%           |\n",
    "\n",
    "In comparison to the first pipeline, our accuracy on training data was +0.81% and our accuracy on testing data was -0.22%.\n",
    "\n",
    "It turns out that our 2nd pipeline was a little too good at detecting patterns in our training data. There's not too much we can do here. TPOT doesn't have a \"chill out on the overfitting\" parameter. Our best bet is just adding more data. More data is going to mean that there's less coincidental patterns in our training subset and therefore less opportunity for overfitting.\n",
    "\n",
    "##### ....so I need to start writing down numbers?\n",
    "\n",
    "Nope! Remember how we used the built in Scikit-Learn MNIST data set? Well that's just a sample of the real thing. Scikit's data set consists of 1797, 8x8 pixel images. The real MNIST dataset is 70,000, 28x28 images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's play with some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here's a link to download the MNIST data from Kaggle](https://www.kaggle.com/oddrationale/mnist-in-csv/downloads/mnist-in-csv.zip/2)\n",
    "\n",
    "If you want to follow along: I've unzipped the files into a directory named \"mnist-data\", within the same directory as this notebook. You can either download and unzip the data yourslef or just follow along in the notebook.\n",
    "\n",
    "Technically we don't need to go get the raw data ourselves. Scikit learn has functions for downloading the entire dataset, but I purposely want a more vanilla approach.\n",
    "\n",
    "Here's how you'd do it with scikit:\n",
    "```\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=mnist-data)\n",
    "```\n",
    "\n",
    "#### Ok, here we go:\n",
    "\n",
    "We going to import pandas, a data analysis python library. Pandas works in units of data called data frames. Pandas is smart enough to load the data from the CSV and understand what the column headings mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...    28x19  28x20  \\\n",
      "0      5    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "2      4    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "3      1    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4      9    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...    28x19  28x20  \\\n",
      "0      7    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1      2    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "2      1    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "3      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4      4    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from our CSV\n",
    "training = pd.read_csv('mnist-data/mnist_train.csv')\n",
    "test = pd.read_csv('mnist-data/mnist_test.csv')\n",
    "\n",
    "# Let's see our first 5 rows:\n",
    "print(training.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned earlier: Our data here is actually 28 X 28 pixel picuture digested into 784 columns, each representing the intensity of a particular pixel. Column number 1 is our label. How many pieces of data come in the full set?\n",
    "\n",
    "FYI: The key ML jargon below is 'shape'. Shape represents the dimensions of the data you're working here. The numbers printed here represent (Nubmber of rows, number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: (60000, 785)\n",
      "test: (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(f'training: {training.shape}')\n",
    "print(f'test: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have 60,000 pieces of traning data and 10,000 for testing. The data already came with the train vs test split. Let's make the label vs data split.\n",
    "\n",
    "We saw in the head command that the label column is literally called 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_labels: (60000,)\n",
      "training_data: (60000, 784)\n",
      "test_labels: (10000,)\n",
      "test_data: (10000, 784)\n",
      "training_labels.head():\n",
      "0    5\n",
      "1    0\n",
      "2    4\n",
      "3    1\n",
      "4    9\n",
      "Name: label, dtype: int64\n",
      "test_data.head():\n",
      "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...    28x19  28x20  \\\n",
      "0    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n",
      "1    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n",
      "2    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n",
      "3    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n",
      "4    0    0    0    0    0    0    0    0    0     0  ...        0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make a new dataframe using only the labels\n",
    "training_labels = training.label\n",
    "# Make a new dataframe, but just drop the labels column\n",
    "# 'axis=1' means drop the column heading too.\n",
    "training_data = training.drop('label', axis=1)\n",
    "test_labels = test.label\n",
    "test_data = test.drop('label', axis=1)\n",
    "\n",
    "# Let's confirm we get the right shapes.\n",
    "# We should expect a single column for the labels and 784 for the data.\n",
    "print(f'training_labels: {training_labels.shape}')\n",
    "print(f'training_data: {training_data.shape}')\n",
    "print(f'test_labels: {test_labels.shape}')\n",
    "print(f'test_data: {test_data.shape}')\n",
    "\n",
    "# Let's also give the data a visual once-over\n",
    "print('training_labels.head():')\n",
    "print(training_labels.head())\n",
    "print('test_data.head():')\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 784 columns is....boring\n",
    "\n",
    "Let's have a little data exploration side bar.\n",
    "\n",
    "1. I want to see what our numbers actually look like. Creating a handwritten digit reconizer on handwritten digits that you've never seen feels silly.\n",
    "\n",
    "2. Once we have a model trained, I'd like to explore what digits it gets wrong. What if I can't tell what the digit is either?\n",
    "\n",
    "We're going to use matplotlib's imshow for this task. This library is for creating 2D graphs in python.\n",
    "\n",
    "I use the term *features* in the comments below. Note that that's a formal term in machine learning. It really just means the all of the columns of data that get fed into the machine learning algorithm, minus the label or target column. In our case the features are all of the columns representing pixel intensity in our picutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's matplotlib do it's magic inside of the notebook:\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's load a random sample digit from the dataframe.\n",
    "# If you've been actively following along I reccomend mashing that 'Run' button a few times.\n",
    "our_number = training_data.sample(n=1)\n",
    "\n",
    "# Let's take our flat 784 features and reshape it into a 28x28 graph\n",
    "# Note that pandas doesn't have a reshape method, but pandas is built on numpy\n",
    "# and numpy has reshape. Access the numpy methods with values.reshape()\n",
    "our_number_shaped = our_number.values.reshape(28, 28)\n",
    "\n",
    "# cmap=matplotlib.cm.binary: \"Make bigger numbers darker\"\n",
    "plt.imshow(our_number_shaped, cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to see what this puppy can do\n",
    "\n",
    "We now have a bigger, meaner dataset. Let run the something akin to our \"do it big\" pipeline, but incorporating our lessons learned.\n",
    "\n",
    "I'm not going to mark this code up as much. We've already explored it before. Just note:\n",
    "\n",
    "1. The use of our new data.\n",
    "2. Given the increased size of the dataset, I'm lowering the population size back down to 20. This dataset will take much longer per individual pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "Generation 1 - Current best internal CV score: 0.9113000880027429\n",
      "Generation 3 - Current best internal CV score: 0.9115168394202222\n",
      "Generation 4 - Current best internal CV score: 0.9127834949991644\n",
      "Generation 5 - Current best internal CV score: 0.9147335715485821\n",
      "Generation 6 - Current best internal CV score: 0.9152667826606102\n",
      "Generation 13 - Current best internal CV score: 0.9154835187969583\n",
      "Generation 14 - Current best internal CV score: 0.9157668326564613\n",
      "Generation 15 - Current best internal CV score: 0.9165667299923047\n",
      "Generation 17 - Current best internal CV score: 0.9215666886610293\n",
      "Generation 18 - Current best internal CV score: 0.9579333233149008\n",
      "Generation 31 - Current best internal CV score: 0.9617832097310728\n",
      "Generation 37 - Current best internal CV score: 0.9668832906676232\n",
      "Generation 39 - Current best internal CV score: 0.9685000616054886\n",
      "Generation 56 - Current best internal CV score: 0.9691833005267713\n",
      "Generation 57 - Current best internal CV score: 0.96948338808337\n",
      "Generation 61 - Current best internal CV score: 0.9698499186761739\n",
      "Generation 64 - Current best internal CV score: 0.9699834298007317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress: 1855pipeline [54:25:43, 990.44s/pipeline] "
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(max_time_mins=4320, population_size=20, n_jobs=3,\n",
    "                      periodic_checkpoint_folder='./mnist-tpot-checkpoint-3',\n",
    "                      early_stop=150, verbosity=2)\n",
    "tpot.fit(training_data, training_labels)\n",
    "print(tpot.score(test_data, test_labels))\n",
    "tpot.export('tpot_mnist_pipeline_v3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another early stop\n",
    "\n",
    "The middle of the night Windows reboot struck last night. We made it 64 generations, 54 hours, and 96.99% accuracy into the last traning. This will acctually be a good opportunity to look at the pipeline that TPOT produced and get our own numbers for accuracy on the testing data.\n",
    "\n",
    "Remember, we segt out checkoutpoint folder using `periodic_checkpoint_folder='./mnist-tpot-checkpoint-3'`. The most advanced pipeline in that directory is `pipeline_2018.08.15_02-58-33.py`. Here's the code with my comments:\n",
    "\n",
    "```python\n",
    "#Numpy is the scientific calculator of python.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Importing the actual ML alogrithms that will be used by the pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Importing other sklearn utils. Will address lower down.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Importing a few TPOT utils.\n",
    "from tpot.builtins import OneHotEncoder, StackingEstimator\n",
    "\n",
    "# Load your data:\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "# Pull out your features. Note that in this code they assume the label column is named 'target'.\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "# Create the 4 way split.\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=42)\n",
    "\n",
    "# Score on the training set was:0.9699834298007317\n",
    "# We're going to break this down in detail below\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.05, min_samples_leaf=1, min_samples_split=6, n_estimators=100)),\n",
    "    OneHotEncoder(minimum_fraction=0.25, sparse=False),\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(C=25.0, dual=False, penalty=\"l1\")\n",
    ")\n",
    "\n",
    "# Train a model using the new pipeline\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "# Feed test features to the trained model.\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "```\n",
    "\n",
    "### Our pipeline\n",
    "\n",
    "Let's try to make sense of each step in `make_pipeline`.\n",
    "\n",
    "- [StackingEstimator](https://github.com/EpistasisLab/tpot/blob/master/tpot/builtins/stacking_estimator.py) - TPOT class used to create synthetic features to feed into the models. \n",
    "    - [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) - This is the machine learning algorithm that is used to transform the features that are later fed back into other machine learning algorithms. [Random forests](https://en.wikipedia.org/wiki/Random_forest) consist of [decision trees](https://en.wikipedia.org/wiki/Decision_tree_learning). These desicions trees are small machine learning model themselves. Each tree is trained on a random subset of the data. We then combine the output of all of the trees (the forest) for our final output. The fact that all of the smaller models are trained on random sub sets of data helps prevent overfitting.\n",
    "        - bootstrap = Use random samples of data for each tree.\n",
    "        - criterion = This is the function that is used to construct the decision trees. \"gini\" is the default and should be left that way. “entropy”, the alternative, is slower and only slightly better sometimes.\n",
    "        - max_features = The number of features to consider when determining the splits between classes in the classifer (this is at the tree level).\n",
    "        - min_samples_leaf = \"Leaves\" are the classes that the tree will classify the features into. This is saying we need at least 1 sample of a particualr class in that tree in order to create a leaf for the class.\n",
    "        - min_samples_split = The minimum number of samples needed to make the decision to split a leaf.\n",
    "        - n_estimators = The number of trees in the forest.\n",
    "\n",
    "\n",
    "- [OneHotEncoder](https://github.com/EpistasisLab/tpot/blob/master/tpot/builtins/one_hot_encoder.py) - Machine learning models tend to like descrete classes, rather than strings or values. One hot encoding technique for transforming data so that it fits this model better. For example, imagine you have a column that reads 'Car Make' and your individual items in the table have values like 'Chevy' or 'Ford'. One hot encoding creates a column for 'Chevy' and a column for 'Ford'. So your car that previously had \"Car Make: Ford\" would now have \"Chevy: 0, Ford: 1, BMW: 0\". \n",
    "\n",
    "    **Note** These features are not well documented. These are my best guesses\n",
    "    - minimum_fraction = Take the bottom X% of categories and catergorize under 'other'\n",
    "    - sparse = Whether we should assume there will be missing data\n",
    "\n",
    "\n",
    "- [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - Scales all of our feature to be 0-1, from 0-255. Note that at this point we're still transforming our data before feeding it into the final algorithm. We've used models to change the data, but we still don't have models that classify our picutes of digits into numbers yet.\n",
    "\n",
    "\n",
    "- [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) - [Here's a good walkthrough on logistic regression and classification](https://developers.google.com/machine-learning/crash-course/classification/video-lecture). Essentially, our model will calculate the likelihood that each picture is of a particular class. The model when then output the most likely class.\n",
    "\n",
    "    We need to talk about graphs, weights, and regularization to understand these next parameters.\n",
    "    \n",
    "    Machine learning can most simply be thought of as really complex graphs drawn by machines. Imagine you have a simple 2D graph with an X and Y axis. X is your feature and Y is your label. Imagine a scatter of datapoints on your graph. You do your best to draw a line that represents the data. Now if I remove all of the data points, just leave the line you drew, and give you a new value of X, you could give me a rough esimate of the new Y. The line that you drew is essentially a 'model' in machine learning.\n",
    "    \n",
    "    Now we need to exapand our graph to 3D space. Imagine three points floating in the air. These are your X, Y, and Z axis. You have to draw a line through these points. Where do you draw the line? The exact center of the three points? What if one of the values is twice as important as the other? You need to develop a function for determining how heavily you would weight the line toward one datapoint or the other. After you've figured out how to weight your data, you can imagine a series of these 3D points, a (weighted) line drawn through them, and the resulting model snaking around the room.\n",
    "    \n",
    "    Machine learning models do this, but they do it at much higher complexities than can be calcualted by a human. We just used 2D and 3D space. Our model is working with 60,000 pieces of traning data in 784D space.\n",
    "    \n",
    "    So now that we understand that weights are used to determine how strongly certain nodes in our graph are linked, we can talk regularization.\n",
    "\n",
    "    Regularization is another very important concept in machine learning. Large outliers in our data are going to skew results and cause overfitting. We 'regularize' the data by bringing the **weights** all closer to the center (closer to zero). All of our arguements revolve around how the model should regularize. We're telling the model how it shoud tweak weights while it's calculating our model.\n",
    "    \n",
    "    - C = Smaller values mean stronger regularization\n",
    "    - dual = I'm not sure...I can't find any resources that aren't more math than I know. The docs say you can only use this with l2 regularization, and we're using l1, so I don't think this matters anyway.\n",
    "    - penalty = Set l1 or l2 reqularization. L1 will drive weights to zero, whereas l2 will just drive weights close to zero.\n",
    "\n",
    "### Testing our pipeline\n",
    "\n",
    "Due to our early stop we didn't get to see how our newest pipeline performed on the testing data. Let's edit the pipeline code TPOT gave us and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tpot.builtins import OneHotEncoder, StackingEstimator\n",
    "\n",
    "# TPOT's pipeline boilerplate has some expectations around how the data should look.\n",
    "# I'm going just use our code from earlier, updating 'data' to our new 10 cent word, 'feature'.\n",
    "training = pd.read_csv('mnist-data/mnist_train.csv')\n",
    "test = pd.read_csv('mnist-data/mnist_test.csv')\n",
    "training_labels = training.label\n",
    "training_features = training.drop('label', axis=1)\n",
    "test_labels = test.label\n",
    "test_features = test.drop('label', axis=1)\n",
    "\n",
    "# Score on the training set was:0.9699834298007317\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.05, min_samples_leaf=1, min_samples_split=6, n_estimators=100)),\n",
    "    OneHotEncoder(minimum_fraction=0.25, sparse=False),\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(C=25.0, dual=False, penalty=\"l1\")\n",
    ")\n",
    "\n",
    "# This actually trains our model on our pipeline\n",
    "exported_pipeline.fit(training_features, training_labels)\n",
    "# Let's see our accuracy on testing data.\n",
    "print(f'Testing accuracy: {exported_pipeline.score(test_features, test_labels)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How'd we do?\n",
    "\n",
    "Below is the chart with trainging and testing accuracy for all three runs. The third run gave us less accuracy than before, but we were also interrupted early.\n",
    "\n",
    "|Run Num | Training Accuracy | Testing Accuracy|\n",
    "|--------|-------------------|-----------------|\n",
    "|1       |98.59%             |98.66%           |\n",
    "|2       |99.40%             |98.44%           |\n",
    "|3       |96.99%             |97.16%           |\n",
    "\n",
    "### Let's dig through our data\n",
    "\n",
    "Below I'm creating a function to pull out a specific number, print its index, label, and prediction, then plots the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 5003\n",
      "Label: 8\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABLNJREFUeJzt3VtSGzsUQNHrW8wLPDLwyICRORNIt1wo/TB7rV8T2klllz5OS7rc7/f/gJ7/j/4CwDHED1HihyjxQ5T4IUr8ECV+iBI/RIkfol52fp7XCWF7l0d+yMoPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfoh6OfoLcG5fX19Tn99utx8/+/Pzc/Xzt7e3H//uj4+Pqd898+yzsPJDlPghSvwQJX6IEj9EiR+ixA9Rl/v9vufzdn0Y43n2zBz+aDP/dy+Xy9Sz39/fVz8f/btv7KG/nJUfosQPUeKHKPFDlPghSvwQZUvvExiNjb6/vxc/G225PbPZbbMHj9tOz8oPUeKHKPFDlPghSvwQJX6IEj9EmfPvYPZ46yNn9aOtq1s685x+7d2KZ2HlhyjxQ5T4IUr8ECV+iBI/RIkfosz5dzB7zfWM0Z740TXY/N3r6+vRX2GalR+ixA9R4oco8UOU+CFK/BAlfogy5//ljtyPv7XZcxLWjN6POPNZA4+y8kOU+CFK/BAlfogSP0SJH6LED1GX+/2+5/N2fdhZjObR1+t1ny/yA6P3BLacdx/57zY652D0HsDBLo/8kJUfosQPUeKHKPFDlPghSvwQZdR3As88ChxZG5kdeTX5kSPMHRj1AcvED1HihyjxQ5T4IUr8ECV+iDLn/wXWZtIzx1c/u7V3DE6+JXeWOT+wTPwQJX6IEj9EiR+ixA9R4ococ/64y+WhkfApPfnx2lsy5weWiR+ixA9R4oco8UOU+CFK/BD1cvQXYFtnPn9+NIcfna0fnuP/E1Z+iBI/RIkfosQPUeKHKPFDlPghypz/F7her4ufbXnH/dbM8bdl5Yco8UOU+CFK/BAlfogSP0Q5uvsJbHm89uy22rUx46yd/2/+Jo7uBpaJH6LED1HihyjxQ5T4IUr8EGVL7wlsOSsfzfFH11w/85Zg1ln5IUr8ECV+iBI/RIkfosQPUeKHKHP+HYyuyZ6dpa/tuZ+9onvLOf/orAC2ZeWHKPFDlPghSvwQJX6IEj9EiR+izPl3cLvdpv78aB4+M8sfzfFnvzvnZeWHKPFDlPghSvwQJX6IEj9EuaJ7B7NXbI+O1x4dz71my+u/R1zBvRlXdAPLxA9R4oco8UOU+CFK/BAlfoiypfcJjK7wXpvzH33F9ugdBY5j5Yco8UOU+CFK/BAlfogSP0SJH6Ls59/B6GjtZz4ee3SWgDn/IeznB5aJH6LED1HihyjxQ5T4IUr8EGXOfwKjPfej/fxb2vLOADZjzg8sEz9EiR+ixA9R4oco8UOU+CHKnB9+H3N+YJn4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6Jedn7eQ0cKA9uz8kOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9RfwBcy8Yl2y0VAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_prediction(index, test_features, test_labels):\n",
    "\n",
    "    # iloc is a pandas method that allows to access dataframe rows by index number\n",
    "    our_number = test_features.iloc[index]\n",
    "\n",
    "    # Reshape our data. We need a 28x28 array for graphing and a single row for prediction.\n",
    "    our_number_shaped_for_graphing = our_number.values.reshape(28, 28)\n",
    "    our_number_shaped_for_prediction = our_number.values.reshape(1, -1)\n",
    "\n",
    "    print(f'Index: {index}')\n",
    "    print(f'Label: {test_labels.iloc[index]}')\n",
    "    # exported_pipeline.predict does our actual prediction.\n",
    "    # This returns a list, so we're just grabbing the single return value with [0]\n",
    "    print(f'Prediction: {exported_pipeline.predict(our_number_shaped_for_prediction)[0]}')\n",
    "    plt.imshow(our_number_shaped_for_graphing, cmap=matplotlib.cm.binary)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Just a quick test\n",
    "index = 5003\n",
    "print_prediction(index, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the model get wrong?\n",
    "\n",
    "I'd like to see some examples of numbers the model gets wrong. Let's print out the first 20 incorrect digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 124\n",
      "Label: 7\n",
      "Prediction: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 222\n",
      "Label: 2\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 241\n",
      "Label: 9\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 247\n",
      "Label: 4\n",
      "Prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 259\n",
      "Label: 6\n",
      "Prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 320\n",
      "Label: 9\n",
      "Prediction: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABUpJREFUeJzt3T9r1M0agOGsRA02CiKCrV9BUCTWNoIoCIJW0S9hZ2Ftqfint1PQ0s7WINZWkkZRFEGsjOzbnFPurCd7suHNfV3ts7PzK3JnisluJtPpdAXoObDXDwDsDfFDlPghSvwQJX6IEj9EiR+ixA9R4oeo1SXv588JYfdN/uZFTn6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFD1OpePwCLe/v27czZ48ePh2s/fPgwnJ8+fXo4v3r16nB+9uzZmbMTJ04M17K7nPwQJX6IEj9EiR+ixA9R4oeoyXQ6XeZ+S91sv/j06dNwfu7cuZmzra2t4drV1fFt7/b29nA+z5kzZ2bO7t+/P1x74cKFhfYOm/zNi5z8ECV+iBI/RIkfosQPUeKHKPFDlI/0/gscODD+Hf3z58+Zs2PHjg3XPnv2bDj/8ePHcH7nzp3hfHNzc+bs5cuXw7Xu+XeXkx+ixA9R4oco8UOU+CFK/BAlfohyz/8vcPLkyeF8dB8+7y593uf5r1+/Ppyvr68P5w8ePJg5e/jw4XDt+fPnh/MrV64M54w5+SFK/BAlfogSP0SJH6LED1Hihyj3/PvAjRs3Zs7m3fPfunVrOL979+5wPu/93717N3P269ev4dp5cxbj5Ico8UOU+CFK/BAlfogSP0SJH6Lc8+8DR44cmTmbTMb/qn1ra2s439jY2NEz/dfa2trM2dOnT4drb968udDejDn5IUr8ECV+iBI/RIkfosQPUZPpdLrM/Za6GSsrz58/H87fv38/nN+7d284n/fzM/pa8Tdv3gzXsmPj+93/cPJDlPghSvwQJX6IEj9EiR+ixA9R7vkZOnTo0HD++/fv4fzJkyczZ7dv397RMzGXe35gNvFDlPghSvwQJX6IEj9EiR+ifHU3u+rgwYN7/QjM4OSHKPFDlPghSvwQJX6IEj9EiR+i3PPHffv2bThf9Psejh8/vtB6do+TH6LED1HihyjxQ5T4IUr8ECV+iHLPH/fq1avhfHt7ezg/fPjwcH7p0qX/+ZlYDic/RIkfosQPUeKHKPFDlPghylVf3OfPnxdav7Gx8X96EpbNyQ9R4oco8UOU+CFK/BAlfogSP0S559/n5n0196NHjxZ6/2vXri20nr3j5Ico8UOU+CFK/BAlfogSP0SJH6Lc8+9zX758Gc4/fvy40PsfPXp0ofXsHSc/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFqMp1Ol7nfUjdjZeX79+/D+cWLF4fzzc3N4XxtbW04X19fnzl7/fr1cC07NvmbFzn5IUr8ECV+iBI/RIkfosQPUeKHKPf8cV+/fh3OT506NZz/+fNnOH/x4sXM2eXLl4dr2TH3/MBs4oco8UOU+CFK/BAlfohy1Qf7j6s+YDbxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+iVpe83199zhjYfU5+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IeofAkihcTe1ZagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 321\n",
      "Label: 2\n",
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 340\n",
      "Label: 5\n",
      "Prediction: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 381\n",
      "Label: 3\n",
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 445\n",
      "Label: 6\n",
      "Prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 447\n",
      "Label: 4\n",
      "Prediction: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 448\n",
      "Label: 9\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 449\n",
      "Label: 3\n",
      "Prediction: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 495\n",
      "Label: 8\n",
      "Prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 578\n",
      "Label: 3\n",
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 582\n",
      "Label: 8\n",
      "Prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 646\n",
      "Label: 2\n",
      "Prediction: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABPxJREFUeJzt3a1uVFsAhuEzJ4QEg2gCCfiSIFGIpgpDSAVcAT/BQDFVXAICLAEFnoS0DoMkSAwCgymgcOCakPSoI2f1B7pp+z6P/Tqzt3mzxJ6Zzra3t/8Bev792zcA/B3ihyjxQ5T4IUr8ECV+iBI/RIkfosQPUScmvp6PE8LBm+3mj5z8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6ipf7qbQ+bOnTvD/eXLl8P9+vXrw319fX3P98Q0nPwQJX6IEj9EiR+ixA9R4oco8UOU5/xxs9n4vzn/7s7h5eSHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RJ342zfAwdrc3BzuX79+nehOOGyc/BAlfogSP0SJH6LED1HihyjxQ5Tn/Mfc27dvf2t/+PDhcL98+fKe74nDwckPUeKHKPFDlPghSvwQJX6I8qiPodu3bw/3CxcuTHQn/GlOfogSP0SJH6LED1HihyjxQ5T4Icpz/mPg1atXc7e7d+8OX/vixYvh7jn+8eXkhyjxQ5T4IUr8ECV+iBI/RIkfojznPwZWV1fnbrPZbMI74Shx8kOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUb7PfwR8+/ZtuP/69evArr3Te3/+/PnArn3v3r3hvry8PNyfPXu272ufPn16uJ87d264f/nyZbgvLCzM3ba2toavffz48XBfWVkZ7v9z8kOU+CFK/BAlfogSP0SJH6I86jsCHjx4MNx//Pix7/d+9+7dcP/58+dwX1tb2/e1d3L27Nnhvri4ONxv3Lix72svLS0N95s3bw73R48eDferV6/O3b5//z587YcPH4a7R33AkPghSvwQJX6IEj9EiR+ixA9Rs+3t7SmvN+nFjoo3b94M9/v37w/3zc3NP3k7e3Lp0qXhvtNnFEbOnDkz3Hf7PDtoV/+X3ckPUeKHKPFDlPghSvwQJX6IEj9E+T7/IfDx48fhfpDP8Xf6ierXr18P94sXLw738+fP7/memIaTH6LED1HihyjxQ5T4IUr8ECV+iPKcfwIbGxvD/dOnT7/1/teuXZu7nTx5cvja1dXV4X7lypV93ROHn5MfosQPUeKHKPFDlPghSvwQ5ae7JzCbjX9Jeaf91q1bw/3p06dzt1OnTg1fy7Hkp7uB+cQPUeKHKPFDlPghSvwQJX6I8pXeCTx//ny4v3//frg/efJkuHuWz344+SFK/BAlfogSP0SJH6LED1Hihyjf54fjx/f5gfnED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQdWLi680mvh4wh5MfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iPoPI417saXL1Q4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 659\n",
      "Label: 2\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 684\n",
      "Label: 7\n",
      "Prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 717\n",
      "Label: 0\n",
      "Prediction: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the entire testing set\n",
    "test_results = exported_pipeline.predict(test_features)\n",
    "\n",
    "incorrect_predictions = []\n",
    "\n",
    "# Loop through our pandas data and fill out incorrect_predictions with indexs of incorrect guesses\n",
    "for index, digit in test_labels.iteritems():\n",
    "    if digit != test_results[index]:\n",
    "        incorrect_predictions.append(index)\n",
    "\n",
    "# Print out the first 20 incorrect guesses\n",
    "for index in range(20):\n",
    "    index = incorrect_predictions[index]\n",
    "    print_prediction(index, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on the incorrect guesses\n",
    "\n",
    "A few of the predictions aren't great. With many of them, you can tell what the model was 'thinking'. And a few of the handwritten digits seem to be written in an alien language. \n",
    "\n",
    "##### Bad predictions:\n",
    "\n",
    "Indexes 222, 241 and 495 are good examples of just plain bad perdictions. These might not be the best handwriting in the world, but our model should surely regonize these. This really does indicate to me that we have some serious room for improvement in our model. \n",
    "\n",
    "##### I see what you were doing:\n",
    "\n",
    "Indexes 320, 321, and 447 are images that I'm not sure if I would've been right or wrong on. They're ambigious in a way that I'm not suprised the algorithm got them wrong, but these might be potential accuracy points that could be picked up.\n",
    "\n",
    "##### New, alien languages:\n",
    "\n",
    "Indexes 582 and 646 are proof that we won't ever get 100% accuracy. There's no way I would expect even a human to get these right.\n",
    "\n",
    "# That's it\n",
    "\n",
    "We've trained 3 different models that are capable of reading hand written digits, explored the data, and covered some machine learning basics.\n",
    "\n",
    "I'm considering coming back to this notebook to make an actual tool where you could take a picture of a handwritten digit, upload it to a website, and get a prediction, but I've other things to work on for now.\n",
    "\n",
    "Here's some considerations to chew on when thinking about how you would turn this into a product:\n",
    "\n",
    "- How would you get the picutres into the right format? You'd have to take any picture that someone gave you, turn it into a 28x28 pixel, black and white picture, and convert the pixel intensity to a 0-255 scale. What if they used black paper with a white pen? What if the picture wasn't centered? \n",
    "\n",
    "- How would you export the model? As it currently stands, you don't actually have a trained model that you could move around. You literally have to train the model whenever you want to use it. You could run it as a deamon on a server and make prediction on the fly, but you'd still have to re-train on every reboot. You'd probably use [pickle](http://scikit-learn.org/stable/modules/model_persistence.html), but there are likley better methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
