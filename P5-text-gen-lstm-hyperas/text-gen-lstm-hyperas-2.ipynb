{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Text Generation with Recurrent Neural Networks, LSTM, and Hyperas\n",
    "\n",
    "## Hyperas\n",
    "\n",
    "Hyperas is used for automated machine learning tuning in keras. It's based on the hyperopt library, with a focus on simplification and focus on keras.\n",
    "\n",
    "The concepts here are going to be pretty simple. The main differences you're going to see between this and our previous notebooks are:\n",
    "\n",
    "1. We have to use actual data creation and model creation functions.\n",
    "    - The data function ensures that we only have to load our data once. We have to return the feautres and labels in a particualr order.\n",
    "    - The model function defines our model and the hyperparameter tunings that we want to try.\n",
    "2. We'll plug the data and model functions into a hyperas function that loads the data and tunes the model.\n",
    "\n",
    "There aren't any new machine learning concpets in this notebook, but this tool will be invaluable for finding the best model for any future project.\n",
    "\n",
    "The only real Hyperas notes I have are:\n",
    "\n",
    "- tpe - This is the optimization algorithm we'll be using. You can use any algorithm that hyperopt supports. TPE is Tree-structured Parzen Estimator, it's more than just a random search, but most importantly: It's what the docs use.\n",
    "- Trials - this is a hyperopt trials object that has to be passed to hyperas.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "This function is a little nasty. Hyperas can handle nested function calls, but it doesn't love it. I've opted for one large, flat function.\n",
    "\n",
    "- I originally had the embeddings loading with the model, but they were having to reload on every itereation. These take around a minute to load, so the entire process is faster with embeddings loaded as data.\n",
    "- There are sveral layers of abstraction between our code and hyperopt. Hyperas was being annoying about passing variables between functions. Hence, the need to 'global' some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    print(f'data')\n",
    "    global training_length\n",
    "    training_length = 3\n",
    "    tweet_data = pd.read_csv('trump_tweets.csv')\n",
    "\n",
    "    entire_corpus = []\n",
    "    for index, tweet in tweet_data.iterrows():\n",
    "        entire_corpus.append(str(tweet['text']))\n",
    "    \n",
    "    cleaned = []\n",
    "    for tweet in entire_corpus:\n",
    "        tweet = re.sub(r'http.*\\s', '', tweet)\n",
    "        tweet = re.sub(r'http.*$', '', tweet)\n",
    "        tweet = re.sub(r'http', '', tweet)\n",
    "        cleaned.append(tweet)\n",
    "        \n",
    "    entire_corpus = cleaned\n",
    "        \n",
    "    tokenizer = Tokenizer(filters=str('!\"$%&()*+,-./:;<=>?@[\\]^_`{|}~\\r\\n'),\n",
    "                          lower=True,\n",
    "                          split=' ',\n",
    "                          char_level=False)\n",
    "    \n",
    "    tokenizer.fit_on_texts(entire_corpus)\n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    reverse_index_word = tokenizer.index_word\n",
    "    global number_of_words\n",
    "    number_of_words = len(word_index) + 1\n",
    "    word_counts = tokenizer.word_counts\n",
    "    \n",
    "    tokenized = tokenizer.texts_to_sequences(entire_corpus)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for sequence in tokenized:\n",
    "        for index in range(training_length, len(sequence)):\n",
    "            extract = sequence[index - training_length:index + 1]\n",
    "            features.append(extract[:-1])\n",
    "            labels.append(extract[-1])\n",
    "    \n",
    "    features = np.array(features)\n",
    "    \n",
    "    label_placeholder = np.zeros((len(features), number_of_words), dtype = np.int8)\n",
    "    \n",
    "    for example_index, word_idx in enumerate(labels):\n",
    "        label_placeholder[example_index, word_idx] = 1\n",
    "    \n",
    "    labels = label_placeholder\n",
    "    \n",
    "    train_percent = int(round(float(features.shape[0]) * 0.9))\n",
    "    \n",
    "    x_train = features[:train_percent]\n",
    "    y_train = labels[:train_percent]\n",
    "    x_test = features[train_percent:]\n",
    "    y_test = labels[train_percent:]\n",
    "    \n",
    "    with open('trump_word_dict_tokenized2.json', 'w') as file:\n",
    "        output = json.dumps(tokenizer.word_index, indent=4)\n",
    "        file.write(output)\n",
    "    \n",
    "    with open('trump_word_dict_reverse2.json', 'w') as file:\n",
    "        output = json.dumps(tokenizer.index_word, indent=4)\n",
    "        file.write(output)\n",
    "        \n",
    "    print(f'embeddings')\n",
    "    global pretrained_embeddings\n",
    "    glove_vectors = 'glove.6B/glove.6B.100d.txt'\n",
    "    glove = np.loadtxt(glove_vectors, dtype='str', comments=None, encoding='utf8')\n",
    "    vectors = glove[:, 1:].astype('float')\n",
    "    words = glove[:, 0]\n",
    "    del glove\n",
    "    word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
    "    pretrained_embeddings = np.zeros((number_of_words, vectors.shape[1]))\n",
    "    with open('trump_word_dict_tokenized.json', 'r') as file:\n",
    "        word_index = json.loads(file.read())\n",
    "    for index, word in enumerate(word_index.keys()):\n",
    "        vector = word_lookup.get(word, None)\n",
    "        if vector is not None:\n",
    "            pretrained_embeddings[index + 1, :] = vector\n",
    "    gc.enable()\n",
    "    del vectors\n",
    "    gc.collect()\n",
    "    pretrained_embeddings = pretrained_embeddings / np.linalg.norm(pretrained_embeddings, axis=1).reshape((-1, 1))\n",
    "    pretrained_embeddings = np.nan_to_num(pretrained_embeddings)\n",
    "    print(f'embeddings complete')\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We're going to talk syntax and resoning here, rather than cluttering up the code.\n",
    "\n",
    "- **{{}}** - This is the basic syntax for telling hyperas \"here's some params I want you to tune\".\n",
    "- **{{choice([1, 2])}}** - Syntax for passing hyperas a list of options to chosse from. 1 or 2 in this case.\n",
    "- **{{uniform(0, 1)}}** - Hyperas will decide on it's own, along a uniform distribution of the values you pass.\n",
    "- **if {{choice(['one', 'two'])}} == 'two'** - Pointing out that we don't have to only use hyperas directly on hyperparameters.\n",
    "    - At 2 points I use this to try out entire layers, at both the LSTM and Dense level. Notice that the Dense if adds a Dense and a dropout.\n",
    "    - At 1 point I use this to decide on a learning rate and learning rate decay. This is because I don't want hyperas trying the lowest LRs with the highest LR decay.\n",
    "- **lstm_size = {{choice([64, 128])}}** - Using hyperas to set a variable to plug in later.\n",
    "    - Honestly, I didn't really want to do this. I ran into an OOM error at really high trial levels and did this to help reduce the search space.\n",
    "- **[EarlyStopping(monitor='val_acc', patience=2)]** - We need this to increase the search speed. Hyperas is evaluating accuracy, so I aslo used accuracy here. Accuracy seems to bounce a little less than loss and we have a lot of iterations to try here, so I used 2 patience.\n",
    "- **'loss': -validation_acc**, - You may notice that at the end of the function we're passing a negative accuracy. This is because hyperas will always try to lower the value you pass to it. We actually want our value to go up, so we're passing its negative for hyperas to assess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(input_dim=number_of_words,\n",
    "                        input_length = training_length,\n",
    "                        output_dim=100,\n",
    "                        weights=[pretrained_embeddings],\n",
    "                        trainable={{choice([False, True])}},\n",
    "                        mask_zero=True\n",
    "                       ))\n",
    "    \n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    \n",
    "    lstm_size = {{choice([64, 128, 256])}}\n",
    "    \n",
    "    if {{choice(['one_lstm', 'two_lstm'])}} == 'two_lstm':\n",
    "         model.add(LSTM(lstm_size, return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(lstm_size, return_sequences=False))\n",
    "    \n",
    "    model.add(Dense({{choice([32, 64, 256])}}, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    if {{choice(['one_dense', 'two_dense'])}} == 'two_dense':\n",
    "        model.add(Dense({{choice([32, 64])}}, activation='relu'))\n",
    "\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(number_of_words, activation='softmax'))\n",
    "    \n",
    "    if {{choice(['norm_lr', 'high_lr'])}} == 'high_lr':\n",
    "        optimizer = Adam(lr={{choice([0.1, 0.2])}},\n",
    "                     decay={{choice([0.001, 0.01])}})\n",
    "    else:\n",
    "        optimizer = Adam(lr={{choice([0.001, 0.01])}},\n",
    "                     decay={{choice([0.0, 0.0001])}})\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_acc', patience=2)]\n",
    "    \n",
    "    \n",
    "    result = model.fit(x_train, y_train, \n",
    "                       batch_size=4096,\n",
    "                       epochs=50,\n",
    "                       verbose=1,\n",
    "                       validation_data=(x_test, y_test),\n",
    "                       callbacks=callbacks)\n",
    "    \n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_acc'])\n",
    "    \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "- I originally started with 100 evals but woke up to an OOM that happened around 57. I did some tuning to reduce the search space and cut the evals to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings complete\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import json\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import re\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import gc\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'trainable': hp.choice('trainable', [False, True]),\n",
      "        'lstm_size': hp.choice('lstm_size', [64, 128]),\n",
      "        'lstm_size_1': hp.choice('lstm_size_1', ['one_lstm', 'two_lstm']),\n",
      "        'Dense': hp.choice('Dense', [32, 64]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dropout_1': hp.choice('Dropout_1', ['one_dense', 'two_dense']),\n",
      "        'Dense_1': hp.choice('Dense_1', [32, 64]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'Dropout_3': hp.choice('Dropout_3', ['norm_lr', 'high_lr']),\n",
      "        'lr': hp.choice('lr', [0.1, 0.2]),\n",
      "        'decay': hp.choice('decay', [0.001, 0.01]),\n",
      "        'decay_1': hp.choice('decay_1', [0.001, 0.01]),\n",
      "        'decay_2': hp.choice('decay_2', [0.0, 0.0001]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: print(f'data')\n",
      "   3: global training_length\n",
      "   4: training_length = 3\n",
      "   5: tweet_data = pd.read_csv('trump_tweets.csv')\n",
      "   6: \n",
      "   7: entire_corpus = []\n",
      "   8: for index, tweet in tweet_data.iterrows():\n",
      "   9:     entire_corpus.append(str(tweet['text']))\n",
      "  10: \n",
      "  11: cleaned = []\n",
      "  12: for tweet in entire_corpus:\n",
      "  13:     tweet = re.sub(r'http.*\\s', '', tweet)\n",
      "  14:     tweet = re.sub(r'http.*$', '', tweet)\n",
      "  15:     tweet = re.sub(r'http', '', tweet)\n",
      "  16:     cleaned.append(tweet)\n",
      "  17:     \n",
      "  18: entire_corpus = cleaned\n",
      "  19:     \n",
      "  20: tokenizer = Tokenizer(filters=str('!\"$%&()*+,-./:;<=>?@[\\]^_`{|}~\\r\\n'),\n",
      "  21:                       lower=True,\n",
      "  22:                       split=' ',\n",
      "  23:                       char_level=False)\n",
      "  24: \n",
      "  25: tokenizer.fit_on_texts(entire_corpus)\n",
      "  26: \n",
      "  27: word_index = tokenizer.word_index\n",
      "  28: reverse_index_word = tokenizer.index_word\n",
      "  29: global number_of_words\n",
      "  30: number_of_words = len(word_index) + 1\n",
      "  31: word_counts = tokenizer.word_counts\n",
      "  32: \n",
      "  33: tokenized = tokenizer.texts_to_sequences(entire_corpus)\n",
      "  34: \n",
      "  35: features = []\n",
      "  36: labels = []\n",
      "  37: \n",
      "  38: for sequence in tokenized:\n",
      "  39:     for index in range(training_length, len(sequence)):\n",
      "  40:         extract = sequence[index - training_length:index + 1]\n",
      "  41:         features.append(extract[:-1])\n",
      "  42:         labels.append(extract[-1])\n",
      "  43: \n",
      "  44: features = np.array(features)\n",
      "  45: \n",
      "  46: label_placeholder = np.zeros((len(features), number_of_words), dtype = np.int8)\n",
      "  47: \n",
      "  48: for example_index, word_idx in enumerate(labels):\n",
      "  49:     label_placeholder[example_index, word_idx] = 1\n",
      "  50: \n",
      "  51: labels = label_placeholder\n",
      "  52: \n",
      "  53: train_percent = int(round(float(features.shape[0]) * 0.9))\n",
      "  54: \n",
      "  55: x_train = features[:train_percent]\n",
      "  56: y_train = labels[:train_percent]\n",
      "  57: x_test = features[train_percent:]\n",
      "  58: y_test = labels[train_percent:]\n",
      "  59: \n",
      "  60: with open('trump_word_dict_tokenized2.json', 'w') as file:\n",
      "  61:     output = json.dumps(tokenizer.word_index, indent=4)\n",
      "  62:     file.write(output)\n",
      "  63: \n",
      "  64: with open('trump_word_dict_reverse2.json', 'w') as file:\n",
      "  65:     output = json.dumps(tokenizer.index_word, indent=4)\n",
      "  66:     file.write(output)\n",
      "  67:     \n",
      "  68: print(f'embeddings')\n",
      "  69: global pretrained_embeddings\n",
      "  70: glove_vectors = 'glove.6B/glove.6B.100d.txt'\n",
      "  71: glove = np.loadtxt(glove_vectors, dtype='str', comments=None, encoding='utf8')\n",
      "  72: vectors = glove[:, 1:].astype('float')\n",
      "  73: words = glove[:, 0]\n",
      "  74: del glove\n",
      "  75: word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
      "  76: pretrained_embeddings = np.zeros((number_of_words, vectors.shape[1]))\n",
      "  77: with open('trump_word_dict_tokenized.json', 'r') as file:\n",
      "  78:     word_index = json.loads(file.read())\n",
      "  79: for index, word in enumerate(word_index.keys()):\n",
      "  80:     vector = word_lookup.get(word, None)\n",
      "  81:     if vector is not None:\n",
      "  82:         pretrained_embeddings[index + 1, :] = vector\n",
      "  83: gc.enable()\n",
      "  84: del vectors\n",
      "  85: gc.collect()\n",
      "  86: pretrained_embeddings = pretrained_embeddings / np.linalg.norm(pretrained_embeddings, axis=1).reshape((-1, 1))\n",
      "  87: pretrained_embeddings = np.nan_to_num(pretrained_embeddings)\n",
      "  88: print(f'embeddings complete')\n",
      "  89: \n",
      "  90: \n",
      "  91: \n",
      "  92: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     model = Sequential()\n",
      "   5: \n",
      "   6:     model.add(Embedding(input_dim=number_of_words,\n",
      "   7:                         input_length = training_length,\n",
      "   8:                         output_dim=100,\n",
      "   9:                         weights=[pretrained_embeddings],\n",
      "  10:                         trainable=space['trainable'],\n",
      "  11:                         mask_zero=True\n",
      "  12:                        ))\n",
      "  13:     \n",
      "  14:     model.add(Masking(mask_value=0.0))\n",
      "  15:     \n",
      "  16:     lstm_size = space['lstm_size']\n",
      "  17:     \n",
      "  18:     if space['lstm_size_1'] == 'two_lstm':\n",
      "  19:          model.add(LSTM(lstm_size, return_sequences=True))\n",
      "  20: \n",
      "  21:     model.add(LSTM(lstm_size, return_sequences=False))\n",
      "  22:     \n",
      "  23:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  24:     \n",
      "  25:     model.add(Dropout(space['Dropout']))\n",
      "  26:     \n",
      "  27:     if space['Dropout_1'] == 'two_dense':\n",
      "  28:         model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "  29: \n",
      "  30:         model.add(Dropout(space['Dropout_2']))\n",
      "  31:     \n",
      "  32:     model.add(Dense(number_of_words, activation='softmax'))\n",
      "  33:     \n",
      "  34:     if space['Dropout_3'] == 'high_lr':\n",
      "  35:         optimizer = Adam(lr=space['lr'],\n",
      "  36:                      decay=space['decay'])\n",
      "  37:     else:\n",
      "  38:         optimizer = Adam(lr=space['decay_1'],\n",
      "  39:                      decay=space['decay_2'])\n",
      "  40:     \n",
      "  41:     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
      "  42:     \n",
      "  43:     callbacks = [EarlyStopping(monitor='val_acc', patience=2)]\n",
      "  44:     \n",
      "  45:     \n",
      "  46:     result = model.fit(x_train, y_train, \n",
      "  47:                        batch_size=4096,\n",
      "  48:                        epochs=50,\n",
      "  49:                        verbose=1,\n",
      "  50:                        validation_data=(x_test, y_test),\n",
      "  51:                        callbacks=callbacks)\n",
      "  52:     \n",
      "  53:     #get the highest validation accuracy of the training epochs\n",
      "  54:     validation_acc = np.amax(result.history['val_acc'])\n",
      "  55:     \n",
      "  56:     print('Best validation acc of epoch:', validation_acc)\n",
      "  57:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  58: \n",
      "data\n",
      "embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\Desktop\\projects\\notebooks\\P5-text-gen-lstm-hyperas\\temp_model.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pretrained_embeddings = pretrained_embeddings / np.linalg.norm(pretrained_embeddings, axis=1).reshape((-1, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings complete\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 50s 142us/step - loss: 7.5003 - acc: 0.0384 - val_loss: 7.5586 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1544 - acc: 0.0411 - val_loss: 7.5653 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1329 - acc: 0.0411 - val_loss: 7.5798 - val_acc: 0.0425\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1205 - acc: 0.0412 - val_loss: 7.5992 - val_acc: 0.0424\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1100 - acc: 0.0412 - val_loss: 7.5966 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04245451306125378\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 7.5047 - acc: 0.0381 - val_loss: 7.5480 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 7.0747 - acc: 0.0433 - val_loss: 7.4264 - val_acc: 0.0454\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8486 - acc: 0.0577 - val_loss: 7.2404 - val_acc: 0.0630\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.6510 - acc: 0.0709 - val_loss: 7.1715 - val_acc: 0.0668\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.5287 - acc: 0.0768 - val_loss: 7.1156 - val_acc: 0.0723\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.4295 - acc: 0.0837 - val_loss: 7.0722 - val_acc: 0.0776\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 6.3479 - acc: 0.0882 - val_loss: 7.0483 - val_acc: 0.0802\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 39s 111us/step - loss: 6.2779 - acc: 0.0916 - val_loss: 7.0385 - val_acc: 0.0832\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 39s 111us/step - loss: 6.2177 - acc: 0.0948 - val_loss: 7.0096 - val_acc: 0.0860\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 39s 111us/step - loss: 6.1668 - acc: 0.0977 - val_loss: 6.9980 - val_acc: 0.0876\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 39s 112us/step - loss: 6.1230 - acc: 0.0993 - val_loss: 6.9771 - val_acc: 0.0898\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 39s 112us/step - loss: 6.0825 - acc: 0.1019 - val_loss: 6.9810 - val_acc: 0.0922\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 39s 112us/step - loss: 6.0434 - acc: 0.1041 - val_loss: 6.9670 - val_acc: 0.0920\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 39s 111us/step - loss: 6.0105 - acc: 0.1055 - val_loss: 6.9576 - val_acc: 0.0936\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 39s 112us/step - loss: 5.9787 - acc: 0.1072 - val_loss: 6.9517 - val_acc: 0.0938\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 39s 112us/step - loss: 5.9487 - acc: 0.1090 - val_loss: 6.9528 - val_acc: 0.0981\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 5.9232 - acc: 0.1102 - val_loss: 6.9535 - val_acc: 0.0979\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.8963 - acc: 0.1113 - val_loss: 6.9497 - val_acc: 0.0978\n",
      "Best validation acc of epoch: 0.09805820290025638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.7187 - acc: 0.0319 - val_loss: 7.5130 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.1964 - acc: 0.0434 - val_loss: 7.5098 - val_acc: 0.0467\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.1434 - acc: 0.0460 - val_loss: 7.5129 - val_acc: 0.0486\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.1025 - acc: 0.0472 - val_loss: 7.4984 - val_acc: 0.0502\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.0650 - acc: 0.0487 - val_loss: 7.4946 - val_acc: 0.0510\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.0344 - acc: 0.0499 - val_loss: 7.4906 - val_acc: 0.0509\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 7.0048 - acc: 0.0508 - val_loss: 7.4811 - val_acc: 0.0506\n",
      "Best validation acc of epoch: 0.05101676771485516\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 9.7425 - acc: 0.0193 - val_loss: 9.1357 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 9.2972 - acc: 0.0368 - val_loss: 8.7236 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 9.1425 - acc: 0.0395 - val_loss: 8.5806 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 124us/step - loss: 7.8255 - acc: 0.0305 - val_loss: 7.6069 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1729 - acc: 0.0411 - val_loss: 7.5809 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.1437 - acc: 0.0411 - val_loss: 7.5842 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 7.5211 - acc: 0.0327 - val_loss: 7.5674 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1744 - acc: 0.0386 - val_loss: 7.6023 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.1557 - acc: 0.0396 - val_loss: 7.6020 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 13.6468 - acc: 0.0204 - val_loss: 15.8302 - val_acc: 0.0179\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 13.6817 - acc: 0.0218 - val_loss: 15.8302 - val_acc: 0.0179\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 13.6646 - acc: 0.0220 - val_loss: 15.8302 - val_acc: 0.0179\n",
      "Best validation acc of epoch: 0.017863513596863227\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 126us/step - loss: 7.8315 - acc: 0.0351 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.4949 - acc: 0.0405 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.4505 - acc: 0.0406 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 124us/step - loss: 15.6038 - acc: 0.0152 - val_loss: 15.8972 - val_acc: 0.0137\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 15.5611 - acc: 0.0168 - val_loss: 15.8974 - val_acc: 0.0137\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 15.2186 - acc: 0.0203 - val_loss: 15.7037 - val_acc: 0.0207\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 14.9462 - acc: 0.0210 - val_loss: 15.7842 - val_acc: 0.0207\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 14.8178 - acc: 0.0215 - val_loss: 15.7842 - val_acc: 0.0207\n",
      "Best validation acc of epoch: 0.02071759849672841\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 8.2510 - acc: 0.0293 - val_loss: 7.6558 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.1677 - acc: 0.0411 - val_loss: 7.5713 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.0911 - acc: 0.0411 - val_loss: 7.5437 - val_acc: 0.0425\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.0438 - acc: 0.0433 - val_loss: 7.5186 - val_acc: 0.0478\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.9582 - acc: 0.0489 - val_loss: 7.4396 - val_acc: 0.0536\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 6.8248 - acc: 0.0562 - val_loss: 7.3504 - val_acc: 0.0583\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.6958 - acc: 0.0647 - val_loss: 7.2797 - val_acc: 0.0663\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.5906 - acc: 0.0741 - val_loss: 7.2414 - val_acc: 0.0690\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.5058 - acc: 0.0791 - val_loss: 7.2020 - val_acc: 0.0718\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.4260 - acc: 0.0843 - val_loss: 7.1745 - val_acc: 0.0760\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.3454 - acc: 0.0917 - val_loss: 7.1388 - val_acc: 0.0808\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.2697 - acc: 0.0974 - val_loss: 7.1015 - val_acc: 0.0851\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.1944 - acc: 0.1022 - val_loss: 7.0710 - val_acc: 0.0888\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.1193 - acc: 0.1077 - val_loss: 7.0361 - val_acc: 0.0917\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 6.0471 - acc: 0.1123 - val_loss: 7.0126 - val_acc: 0.0944\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 5.9772 - acc: 0.1175 - val_loss: 6.9885 - val_acc: 0.0976\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.9079 - acc: 0.1218 - val_loss: 6.9681 - val_acc: 0.1017\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.8457 - acc: 0.1271 - val_loss: 6.9511 - val_acc: 0.1027\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.7851 - acc: 0.1312 - val_loss: 6.9361 - val_acc: 0.1035\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.7271 - acc: 0.1353 - val_loss: 6.9229 - val_acc: 0.1057\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.6720 - acc: 0.1394 - val_loss: 6.9237 - val_acc: 0.1063\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6195 - acc: 0.1423 - val_loss: 6.9141 - val_acc: 0.1085\n",
      "Epoch 23/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.5683 - acc: 0.1460 - val_loss: 6.9071 - val_acc: 0.1121\n",
      "Epoch 24/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.5183 - acc: 0.1490 - val_loss: 6.9146 - val_acc: 0.1123\n",
      "Epoch 25/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4703 - acc: 0.1516 - val_loss: 6.9174 - val_acc: 0.1136\n",
      "Epoch 26/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4254 - acc: 0.1547 - val_loss: 6.9216 - val_acc: 0.1146\n",
      "Epoch 27/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3817 - acc: 0.1571 - val_loss: 6.9217 - val_acc: 0.1159\n",
      "Epoch 28/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 5.3400 - acc: 0.1594 - val_loss: 6.9187 - val_acc: 0.1163\n",
      "Epoch 29/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.3016 - acc: 0.1615 - val_loss: 6.9257 - val_acc: 0.1161\n",
      "Epoch 30/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.2609 - acc: 0.1643 - val_loss: 6.9376 - val_acc: 0.1175\n",
      "Epoch 31/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.2210 - acc: 0.1663 - val_loss: 6.9318 - val_acc: 0.1169\n",
      "Epoch 32/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.1846 - acc: 0.1688 - val_loss: 6.9473 - val_acc: 0.1182\n",
      "Epoch 33/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.1494 - acc: 0.1707 - val_loss: 6.9544 - val_acc: 0.1179\n",
      "Epoch 34/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.1131 - acc: 0.1729 - val_loss: 6.9605 - val_acc: 0.1184\n",
      "Epoch 35/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.0824 - acc: 0.1745 - val_loss: 6.9674 - val_acc: 0.1191\n",
      "Epoch 36/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.0501 - acc: 0.1769 - val_loss: 6.9787 - val_acc: 0.1192\n",
      "Epoch 37/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 5.0185 - acc: 0.1779 - val_loss: 6.9829 - val_acc: 0.1201\n",
      "Epoch 38/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 4.9864 - acc: 0.1807 - val_loss: 6.9985 - val_acc: 0.1193\n",
      "Epoch 39/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.9568 - acc: 0.1826 - val_loss: 7.0071 - val_acc: 0.1200\n",
      "Best validation acc of epoch: 0.12010091191420563\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 124us/step - loss: 8.2714 - acc: 0.0257 - val_loss: 7.5937 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.2361 - acc: 0.0409 - val_loss: 7.6338 - val_acc: 0.0423\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1693 - acc: 0.0411 - val_loss: 7.6314 - val_acc: 0.0424\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1576 - acc: 0.0411 - val_loss: 7.6433 - val_acc: 0.0424\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1534 - acc: 0.0411 - val_loss: 7.6443 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 7.4619 - acc: 0.0431 - val_loss: 7.3693 - val_acc: 0.0540\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.9093 - acc: 0.0611 - val_loss: 7.2662 - val_acc: 0.0613\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.7633 - acc: 0.0690 - val_loss: 7.2275 - val_acc: 0.0715\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.6798 - acc: 0.0751 - val_loss: 7.1872 - val_acc: 0.0743\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.6271 - acc: 0.0776 - val_loss: 7.1679 - val_acc: 0.0748\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.5840 - acc: 0.0802 - val_loss: 7.1668 - val_acc: 0.0760\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.5460 - acc: 0.0823 - val_loss: 7.1574 - val_acc: 0.0770\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.5166 - acc: 0.0843 - val_loss: 7.1466 - val_acc: 0.0778\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4920 - acc: 0.0859 - val_loss: 7.1509 - val_acc: 0.0792\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4703 - acc: 0.0865 - val_loss: 7.1417 - val_acc: 0.0793\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4500 - acc: 0.0875 - val_loss: 7.1276 - val_acc: 0.0791\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4339 - acc: 0.0890 - val_loss: 7.1310 - val_acc: 0.0801\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4148 - acc: 0.0901 - val_loss: 7.1189 - val_acc: 0.0808\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.4008 - acc: 0.0906 - val_loss: 7.1223 - val_acc: 0.0829\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.3860 - acc: 0.0917 - val_loss: 7.1153 - val_acc: 0.0832\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.3734 - acc: 0.0922 - val_loss: 7.1197 - val_acc: 0.0825\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.3606 - acc: 0.0932 - val_loss: 7.1114 - val_acc: 0.0832\n",
      "Best validation acc of epoch: 0.08322715476724109\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 126us/step - loss: 14.9254 - acc: 0.0243 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 13.9439 - acc: 0.0290 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 11.6887 - acc: 0.0326 - val_loss: 15.4342 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 125us/step - loss: 8.5618 - acc: 0.0254 - val_loss: 7.5955 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1693 - acc: 0.0411 - val_loss: 7.6140 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1606 - acc: 0.0411 - val_loss: 7.6299 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 127us/step - loss: 7.5914 - acc: 0.0368 - val_loss: 7.5358 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.1418 - acc: 0.0417 - val_loss: 7.4775 - val_acc: 0.0487\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.0244 - acc: 0.0481 - val_loss: 7.4033 - val_acc: 0.0532\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9326 - acc: 0.0529 - val_loss: 7.3909 - val_acc: 0.0546\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 44s 123us/step - loss: 6.8577 - acc: 0.0574 - val_loss: 7.3402 - val_acc: 0.0581\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.7654 - acc: 0.0636 - val_loss: 7.2548 - val_acc: 0.0666\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.6584 - acc: 0.0720 - val_loss: 7.2102 - val_acc: 0.0740\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.5683 - acc: 0.0786 - val_loss: 7.1803 - val_acc: 0.0757\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.4867 - acc: 0.0850 - val_loss: 7.1591 - val_acc: 0.0780\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.4150 - acc: 0.0895 - val_loss: 7.1590 - val_acc: 0.0804\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.3531 - acc: 0.0931 - val_loss: 7.1350 - val_acc: 0.0791\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.3022 - acc: 0.0961 - val_loss: 7.1199 - val_acc: 0.0816\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353176/353176 [==============================] - 42s 118us/step - loss: 6.2482 - acc: 0.0994 - val_loss: 7.1276 - val_acc: 0.0827\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.2020 - acc: 0.1017 - val_loss: 7.1159 - val_acc: 0.0853\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.1601 - acc: 0.1045 - val_loss: 7.1089 - val_acc: 0.0862\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.1236 - acc: 0.1066 - val_loss: 7.1520 - val_acc: 0.0866\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.0862 - acc: 0.1085 - val_loss: 7.1434 - val_acc: 0.0891\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.0528 - acc: 0.1104 - val_loss: 7.1587 - val_acc: 0.0899\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.0212 - acc: 0.1126 - val_loss: 7.1555 - val_acc: 0.0896\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.9948 - acc: 0.1145 - val_loss: 7.1577 - val_acc: 0.0906\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.9655 - acc: 0.1164 - val_loss: 7.1546 - val_acc: 0.0887\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.9416 - acc: 0.1168 - val_loss: 7.1536 - val_acc: 0.0896\n",
      "Best validation acc of epoch: 0.09059171276010873\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 129us/step - loss: 7.5463 - acc: 0.0363 - val_loss: 7.5020 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 7.0610 - acc: 0.0454 - val_loss: 7.4271 - val_acc: 0.0504\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 6.9028 - acc: 0.0533 - val_loss: 7.3310 - val_acc: 0.0596\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.7502 - acc: 0.0661 - val_loss: 7.2501 - val_acc: 0.0731\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.5923 - acc: 0.0802 - val_loss: 7.1540 - val_acc: 0.0763\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.4616 - acc: 0.0885 - val_loss: 7.0985 - val_acc: 0.0851\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.3458 - acc: 0.0963 - val_loss: 7.0688 - val_acc: 0.0872\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.2485 - acc: 0.1014 - val_loss: 7.0271 - val_acc: 0.0882\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.1622 - acc: 0.1061 - val_loss: 7.0172 - val_acc: 0.0916\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 6.0923 - acc: 0.1101 - val_loss: 6.9911 - val_acc: 0.0951\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 6.0268 - acc: 0.1141 - val_loss: 6.9617 - val_acc: 0.0952\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.9711 - acc: 0.1172 - val_loss: 6.9756 - val_acc: 0.0957\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.9162 - acc: 0.1202 - val_loss: 6.9852 - val_acc: 0.0979\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.8736 - acc: 0.1224 - val_loss: 6.9941 - val_acc: 0.0985\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.8301 - acc: 0.1258 - val_loss: 7.0144 - val_acc: 0.0988\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.7898 - acc: 0.1278 - val_loss: 7.0129 - val_acc: 0.0990\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.7528 - acc: 0.1306 - val_loss: 7.0243 - val_acc: 0.0998\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.7198 - acc: 0.1322 - val_loss: 7.0400 - val_acc: 0.0999\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.6914 - acc: 0.1341 - val_loss: 7.0477 - val_acc: 0.1006\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.6613 - acc: 0.1365 - val_loss: 7.0526 - val_acc: 0.1017\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.6332 - acc: 0.1390 - val_loss: 7.0674 - val_acc: 0.1012\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.6114 - acc: 0.1399 - val_loss: 7.0825 - val_acc: 0.1019\n",
      "Epoch 23/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.5901 - acc: 0.1413 - val_loss: 7.0749 - val_acc: 0.1025\n",
      "Epoch 24/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.5656 - acc: 0.1427 - val_loss: 7.0947 - val_acc: 0.1037\n",
      "Epoch 25/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.5416 - acc: 0.1451 - val_loss: 7.1092 - val_acc: 0.1030\n",
      "Epoch 26/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.5261 - acc: 0.1460 - val_loss: 7.1183 - val_acc: 0.1021\n",
      "Best validation acc of epoch: 0.10371540667485658\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.9943 - acc: 0.0276 - val_loss: 7.5914 - val_acc: 0.0425\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 7.1641 - acc: 0.0411 - val_loss: 7.6142 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 7.1591 - acc: 0.0411 - val_loss: 7.6249 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.042454513031065656\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 125us/step - loss: 8.3419 - acc: 0.0227 - val_loss: 7.6474 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.2363 - acc: 0.0411 - val_loss: 7.5705 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 7.1609 - acc: 0.0411 - val_loss: 7.5536 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.8051 - acc: 0.0214 - val_loss: 7.5302 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.1697 - acc: 0.0402 - val_loss: 7.5556 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 7.1469 - acc: 0.0410 - val_loss: 7.5480 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 126us/step - loss: 7.8525 - acc: 0.0303 - val_loss: 7.5043 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1290 - acc: 0.0411 - val_loss: 7.5250 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1178 - acc: 0.0411 - val_loss: 7.5349 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 127us/step - loss: 7.5036 - acc: 0.0380 - val_loss: 7.5045 - val_acc: 0.0436\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9364 - acc: 0.0533 - val_loss: 7.2394 - val_acc: 0.0642\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.5786 - acc: 0.0841 - val_loss: 7.0366 - val_acc: 0.0899\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.2715 - acc: 0.1102 - val_loss: 6.9084 - val_acc: 0.1031\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.0291 - acc: 0.1272 - val_loss: 6.8372 - val_acc: 0.1096\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.8398 - acc: 0.1387 - val_loss: 6.8143 - val_acc: 0.1145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.6831 - acc: 0.1476 - val_loss: 6.7902 - val_acc: 0.1183\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.5456 - acc: 0.1558 - val_loss: 6.7998 - val_acc: 0.1212\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.4273 - acc: 0.1629 - val_loss: 6.8106 - val_acc: 0.1245\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3200 - acc: 0.1682 - val_loss: 6.8239 - val_acc: 0.1236\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.2264 - acc: 0.1739 - val_loss: 6.8704 - val_acc: 0.1245\n",
      "Best validation acc of epoch: 0.12453493698812468\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 44s 126us/step - loss: 7.4952 - acc: 0.0393 - val_loss: 7.4745 - val_acc: 0.0483\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 6.9379 - acc: 0.0520 - val_loss: 7.2505 - val_acc: 0.0651\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.5797 - acc: 0.0843 - val_loss: 7.0324 - val_acc: 0.0910\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 6.2602 - acc: 0.1119 - val_loss: 6.9162 - val_acc: 0.1028\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.0102 - acc: 0.1294 - val_loss: 6.8403 - val_acc: 0.1113\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.8048 - acc: 0.1420 - val_loss: 6.7927 - val_acc: 0.1165\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.6360 - acc: 0.1532 - val_loss: 6.7930 - val_acc: 0.1200\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.4863 - acc: 0.1614 - val_loss: 6.7715 - val_acc: 0.1250\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.3569 - acc: 0.1702 - val_loss: 6.7989 - val_acc: 0.1237\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2421 - acc: 0.1757 - val_loss: 6.8379 - val_acc: 0.1264\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.1406 - acc: 0.1816 - val_loss: 6.8738 - val_acc: 0.1268\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.0460 - acc: 0.1880 - val_loss: 6.9217 - val_acc: 0.1267\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.9620 - acc: 0.1927 - val_loss: 6.9778 - val_acc: 0.1281\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.8852 - acc: 0.1980 - val_loss: 7.0003 - val_acc: 0.1261\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 4.8186 - acc: 0.2019 - val_loss: 7.0545 - val_acc: 0.1256\n",
      "Best validation acc of epoch: 0.12805157733688988\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 126us/step - loss: 7.4990 - acc: 0.0375 - val_loss: 7.5063 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.9472 - acc: 0.0525 - val_loss: 7.2201 - val_acc: 0.0708\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.5583 - acc: 0.0869 - val_loss: 7.0413 - val_acc: 0.0895\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.2563 - acc: 0.1105 - val_loss: 6.8947 - val_acc: 0.1012\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.0114 - acc: 0.1275 - val_loss: 6.8256 - val_acc: 0.1086\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.8146 - acc: 0.1403 - val_loss: 6.7824 - val_acc: 0.1160\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.6462 - acc: 0.1508 - val_loss: 6.7808 - val_acc: 0.1194\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4996 - acc: 0.1595 - val_loss: 6.8012 - val_acc: 0.1233\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3734 - acc: 0.1674 - val_loss: 6.8078 - val_acc: 0.1269\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2589 - acc: 0.1740 - val_loss: 6.8442 - val_acc: 0.1250\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 5.1589 - acc: 0.1796 - val_loss: 6.8991 - val_acc: 0.1260\n",
      "Best validation acc of epoch: 0.12685388123264288\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 130us/step - loss: 7.4758 - acc: 0.0383 - val_loss: 7.4924 - val_acc: 0.0425\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9325 - acc: 0.0523 - val_loss: 7.2260 - val_acc: 0.0678\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.5212 - acc: 0.0889 - val_loss: 7.0138 - val_acc: 0.0927\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.2069 - acc: 0.1144 - val_loss: 6.8769 - val_acc: 0.1031\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.9515 - acc: 0.1328 - val_loss: 6.8114 - val_acc: 0.1113\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.7419 - acc: 0.1461 - val_loss: 6.7728 - val_acc: 0.1198\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.5564 - acc: 0.1577 - val_loss: 6.7579 - val_acc: 0.1211\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.3994 - acc: 0.1669 - val_loss: 6.7850 - val_acc: 0.1243\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.2583 - acc: 0.1747 - val_loss: 6.8127 - val_acc: 0.1259\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.1320 - acc: 0.1821 - val_loss: 6.8577 - val_acc: 0.1264\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.0246 - acc: 0.1886 - val_loss: 6.9059 - val_acc: 0.1273\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.9235 - acc: 0.1942 - val_loss: 6.9720 - val_acc: 0.1270\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8321 - acc: 0.1995 - val_loss: 7.0053 - val_acc: 0.1291\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.7491 - acc: 0.2060 - val_loss: 7.0471 - val_acc: 0.1286\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.6709 - acc: 0.2110 - val_loss: 7.1203 - val_acc: 0.1284\n",
      "Best validation acc of epoch: 0.1291218593129567\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 128us/step - loss: 7.4812 - acc: 0.0373 - val_loss: 7.4870 - val_acc: 0.0480\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9192 - acc: 0.0550 - val_loss: 7.2189 - val_acc: 0.0715\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.5127 - acc: 0.0919 - val_loss: 7.0095 - val_acc: 0.0939\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.1819 - acc: 0.1169 - val_loss: 6.8652 - val_acc: 0.1044\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.9199 - acc: 0.1347 - val_loss: 6.7774 - val_acc: 0.1117\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.7064 - acc: 0.1484 - val_loss: 6.7703 - val_acc: 0.1204\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 5.5232 - acc: 0.1593 - val_loss: 6.7831 - val_acc: 0.1236\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.3656 - acc: 0.1697 - val_loss: 6.8237 - val_acc: 0.1240\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.2237 - acc: 0.1770 - val_loss: 6.8325 - val_acc: 0.1256\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.1019 - acc: 0.1849 - val_loss: 6.8921 - val_acc: 0.1278\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.9866 - acc: 0.1924 - val_loss: 6.9439 - val_acc: 0.1278\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8837 - acc: 0.1981 - val_loss: 6.9920 - val_acc: 0.1280\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.7972 - acc: 0.2039 - val_loss: 7.0313 - val_acc: 0.1285\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.7128 - acc: 0.2095 - val_loss: 7.0856 - val_acc: 0.1300\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.6366 - acc: 0.2151 - val_loss: 7.1323 - val_acc: 0.1274\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.5699 - acc: 0.2197 - val_loss: 7.1815 - val_acc: 0.1278\n",
      "Best validation acc of epoch: 0.12996279505950997\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.4721 - acc: 0.0384 - val_loss: 7.4859 - val_acc: 0.0486\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.8784 - acc: 0.0569 - val_loss: 7.1825 - val_acc: 0.0734\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.4652 - acc: 0.0910 - val_loss: 6.9888 - val_acc: 0.0929\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.1326 - acc: 0.1172 - val_loss: 6.8500 - val_acc: 0.1038\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.8564 - acc: 0.1361 - val_loss: 6.7920 - val_acc: 0.1142\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.6191 - acc: 0.1522 - val_loss: 6.7579 - val_acc: 0.1201\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.4182 - acc: 0.1641 - val_loss: 6.7820 - val_acc: 0.1242\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2458 - acc: 0.1749 - val_loss: 6.8032 - val_acc: 0.1249\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.0932 - acc: 0.1836 - val_loss: 6.8518 - val_acc: 0.1256\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.9528 - acc: 0.1924 - val_loss: 6.8650 - val_acc: 0.1268\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8293 - acc: 0.2012 - val_loss: 6.9620 - val_acc: 0.1264\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 4.7140 - acc: 0.2083 - val_loss: 7.0168 - val_acc: 0.1276\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 4.6134 - acc: 0.2157 - val_loss: 7.0579 - val_acc: 0.1265\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.5238 - acc: 0.2233 - val_loss: 7.1082 - val_acc: 0.1269\n",
      "Best validation acc of epoch: 0.12761836816995287\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 130us/step - loss: 7.4759 - acc: 0.0400 - val_loss: 7.4961 - val_acc: 0.0425\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9313 - acc: 0.0522 - val_loss: 7.2230 - val_acc: 0.0726\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.5122 - acc: 0.0900 - val_loss: 6.9947 - val_acc: 0.0918\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.1809 - acc: 0.1141 - val_loss: 6.8684 - val_acc: 0.1020\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.9139 - acc: 0.1327 - val_loss: 6.7833 - val_acc: 0.1116\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6897 - acc: 0.1480 - val_loss: 6.7605 - val_acc: 0.1172\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.4981 - acc: 0.1606 - val_loss: 6.7833 - val_acc: 0.1196\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.3378 - acc: 0.1699 - val_loss: 6.7857 - val_acc: 0.1221\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.1920 - acc: 0.1779 - val_loss: 6.8101 - val_acc: 0.1231\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.0654 - acc: 0.1849 - val_loss: 6.8577 - val_acc: 0.1269\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.9473 - acc: 0.1935 - val_loss: 6.8935 - val_acc: 0.1259\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8474 - acc: 0.1985 - val_loss: 6.9739 - val_acc: 0.1252\n",
      "Best validation acc of epoch: 0.12685388088481495\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.4483 - acc: 0.0409 - val_loss: 7.4905 - val_acc: 0.0469\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.8244 - acc: 0.0587 - val_loss: 7.1658 - val_acc: 0.0740\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.3291 - acc: 0.1027 - val_loss: 6.9636 - val_acc: 0.0965\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.9525 - acc: 0.1291 - val_loss: 6.8689 - val_acc: 0.1088\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6397 - acc: 0.1517 - val_loss: 6.8294 - val_acc: 0.1172\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.3534 - acc: 0.1717 - val_loss: 6.8310 - val_acc: 0.1227\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.0973 - acc: 0.1878 - val_loss: 6.8966 - val_acc: 0.1255\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8576 - acc: 0.2038 - val_loss: 6.9715 - val_acc: 0.1256\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.6415 - acc: 0.2195 - val_loss: 7.0623 - val_acc: 0.1251\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.4450 - acc: 0.2348 - val_loss: 7.1840 - val_acc: 0.1261\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.2656 - acc: 0.2517 - val_loss: 7.3055 - val_acc: 0.1245\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 4.1057 - acc: 0.2685 - val_loss: 7.4543 - val_acc: 0.1243\n",
      "Best validation acc of epoch: 0.12606391069870357\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 133us/step - loss: 7.4737 - acc: 0.0350 - val_loss: 7.4772 - val_acc: 0.0454\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.8094 - acc: 0.0614 - val_loss: 7.1606 - val_acc: 0.0754\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.3693 - acc: 0.0985 - val_loss: 6.9674 - val_acc: 0.0965\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.0194 - acc: 0.1236 - val_loss: 6.8536 - val_acc: 0.1086\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.7198 - acc: 0.1464 - val_loss: 6.8030 - val_acc: 0.1183\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.4562 - acc: 0.1629 - val_loss: 6.7856 - val_acc: 0.1203\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2328 - acc: 0.1774 - val_loss: 6.8275 - val_acc: 0.1231\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.0339 - acc: 0.1895 - val_loss: 6.8663 - val_acc: 0.1274\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.8522 - acc: 0.2017 - val_loss: 6.9461 - val_acc: 0.1267\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.6854 - acc: 0.2132 - val_loss: 7.0461 - val_acc: 0.1285\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.5377 - acc: 0.2240 - val_loss: 7.0968 - val_acc: 0.1277\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 4.4025 - acc: 0.2360 - val_loss: 7.1975 - val_acc: 0.1258\n",
      "Best validation acc of epoch: 0.12853575256170832\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.4918 - acc: 0.0392 - val_loss: 7.4780 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.9613 - acc: 0.0525 - val_loss: 7.2495 - val_acc: 0.0668\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.6116 - acc: 0.0817 - val_loss: 7.0689 - val_acc: 0.0892\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.3408 - acc: 0.1044 - val_loss: 6.9367 - val_acc: 0.0988\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.1229 - acc: 0.1194 - val_loss: 6.8807 - val_acc: 0.1049\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.9387 - acc: 0.1314 - val_loss: 6.8117 - val_acc: 0.1141\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.7846 - acc: 0.1414 - val_loss: 6.8329 - val_acc: 0.1158\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.6546 - acc: 0.1489 - val_loss: 6.8109 - val_acc: 0.1202\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.5365 - acc: 0.1563 - val_loss: 6.8241 - val_acc: 0.1205\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 5.4374 - acc: 0.1615 - val_loss: 6.8461 - val_acc: 0.1222\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.3461 - acc: 0.1667 - val_loss: 6.8894 - val_acc: 0.1233\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2653 - acc: 0.1708 - val_loss: 6.9166 - val_acc: 0.1230\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.1899 - acc: 0.1760 - val_loss: 6.9562 - val_acc: 0.1243\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1220 - acc: 0.1799 - val_loss: 6.9677 - val_acc: 0.1247\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.0604 - acc: 0.1824 - val_loss: 7.0127 - val_acc: 0.1242\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.0077 - acc: 0.1858 - val_loss: 7.0624 - val_acc: 0.1239\n",
      "Best validation acc of epoch: 0.12466235115959352\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 45s 127us/step - loss: 7.5740 - acc: 0.0372 - val_loss: 7.5463 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1508 - acc: 0.0418 - val_loss: 7.4494 - val_acc: 0.0461\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.9908 - acc: 0.0506 - val_loss: 7.3844 - val_acc: 0.0552\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.8533 - acc: 0.0603 - val_loss: 7.2880 - val_acc: 0.0650\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.7359 - acc: 0.0681 - val_loss: 7.2301 - val_acc: 0.0695\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.6294 - acc: 0.0739 - val_loss: 7.1841 - val_acc: 0.0730\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.5343 - acc: 0.0788 - val_loss: 7.1330 - val_acc: 0.0767\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.4462 - acc: 0.0830 - val_loss: 7.0922 - val_acc: 0.0797\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.3553 - acc: 0.0876 - val_loss: 7.0510 - val_acc: 0.0808\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2738 - acc: 0.0922 - val_loss: 7.0323 - val_acc: 0.0827\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2020 - acc: 0.0957 - val_loss: 6.9965 - val_acc: 0.0859\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.1359 - acc: 0.0994 - val_loss: 6.9922 - val_acc: 0.0870\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0705 - acc: 0.1021 - val_loss: 6.9963 - val_acc: 0.0899\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0130 - acc: 0.1047 - val_loss: 6.9956 - val_acc: 0.0915\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.9665 - acc: 0.1075 - val_loss: 7.0047 - val_acc: 0.0934\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 5.9241 - acc: 0.1094 - val_loss: 6.9851 - val_acc: 0.0941\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.8864 - acc: 0.1108 - val_loss: 6.9894 - val_acc: 0.0946\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8468 - acc: 0.1130 - val_loss: 6.9933 - val_acc: 0.0961\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8174 - acc: 0.1141 - val_loss: 6.9918 - val_acc: 0.0954\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7878 - acc: 0.1157 - val_loss: 7.0019 - val_acc: 0.0958\n",
      "Best validation acc of epoch: 0.09614698556875284\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.4740 - acc: 0.0382 - val_loss: 7.5232 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 6.8965 - acc: 0.0543 - val_loss: 7.1996 - val_acc: 0.0718\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.4087 - acc: 0.0959 - val_loss: 6.9788 - val_acc: 0.0951\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 6.0468 - acc: 0.1216 - val_loss: 6.8517 - val_acc: 0.1090\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.7522 - acc: 0.1426 - val_loss: 6.8000 - val_acc: 0.1158\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.4932 - acc: 0.1603 - val_loss: 6.7929 - val_acc: 0.1225\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2612 - acc: 0.1740 - val_loss: 6.8364 - val_acc: 0.1229\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.0532 - acc: 0.1872 - val_loss: 6.8864 - val_acc: 0.1262\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 4.8686 - acc: 0.1990 - val_loss: 6.9674 - val_acc: 0.1277\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.6961 - acc: 0.2109 - val_loss: 7.0285 - val_acc: 0.1250\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.5370 - acc: 0.2228 - val_loss: 7.1142 - val_acc: 0.1274\n",
      "Best validation acc of epoch: 0.12772029924754805\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 130us/step - loss: 7.5417 - acc: 0.0358 - val_loss: 7.5465 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1639 - acc: 0.0413 - val_loss: 7.4633 - val_acc: 0.0464\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.0015 - acc: 0.0505 - val_loss: 7.3307 - val_acc: 0.0615\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.7960 - acc: 0.0666 - val_loss: 7.2185 - val_acc: 0.0690\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.6265 - acc: 0.0781 - val_loss: 7.1179 - val_acc: 0.0759\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.4788 - acc: 0.0865 - val_loss: 7.0609 - val_acc: 0.0794\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.3593 - acc: 0.0926 - val_loss: 7.0116 - val_acc: 0.0825\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 43s 120us/step - loss: 6.2566 - acc: 0.0973 - val_loss: 6.9813 - val_acc: 0.0871\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 6.1689 - acc: 0.1010 - val_loss: 6.9455 - val_acc: 0.0894\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.0898 - acc: 0.1055 - val_loss: 6.9549 - val_acc: 0.0921\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.0229 - acc: 0.1088 - val_loss: 6.9260 - val_acc: 0.0935\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.9589 - acc: 0.1112 - val_loss: 6.9327 - val_acc: 0.0949\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.9077 - acc: 0.1140 - val_loss: 6.9031 - val_acc: 0.0965\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.8535 - acc: 0.1158 - val_loss: 6.9150 - val_acc: 0.0975\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.8074 - acc: 0.1179 - val_loss: 6.9265 - val_acc: 0.0984\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.7661 - acc: 0.1198 - val_loss: 6.9309 - val_acc: 0.0989\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.7300 - acc: 0.1213 - val_loss: 6.9270 - val_acc: 0.1013\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6942 - acc: 0.1225 - val_loss: 6.9234 - val_acc: 0.1007\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6624 - acc: 0.1233 - val_loss: 6.9392 - val_acc: 0.1019\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6308 - acc: 0.1256 - val_loss: 6.9354 - val_acc: 0.1021\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.6055 - acc: 0.1258 - val_loss: 6.9665 - val_acc: 0.1030\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.5776 - acc: 0.1270 - val_loss: 6.9525 - val_acc: 0.1039\n",
      "Epoch 23/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.5530 - acc: 0.1286 - val_loss: 6.9480 - val_acc: 0.1034\n",
      "Epoch 24/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.5302 - acc: 0.1294 - val_loss: 6.9797 - val_acc: 0.1025\n",
      "Best validation acc of epoch: 0.10391927047197708\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 131us/step - loss: 7.4870 - acc: 0.0407 - val_loss: 7.4740 - val_acc: 0.0478\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.7652 - acc: 0.0667 - val_loss: 7.1750 - val_acc: 0.0758\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.3649 - acc: 0.1000 - val_loss: 7.0504 - val_acc: 0.0928\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.0739 - acc: 0.1203 - val_loss: 6.9592 - val_acc: 0.1023\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.8365 - acc: 0.1358 - val_loss: 6.9106 - val_acc: 0.1089\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 5.6243 - acc: 0.1520 - val_loss: 6.8876 - val_acc: 0.1129\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.4287 - acc: 0.1661 - val_loss: 6.9150 - val_acc: 0.1183\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2508 - acc: 0.1789 - val_loss: 6.9298 - val_acc: 0.1210\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.0852 - acc: 0.1903 - val_loss: 6.9817 - val_acc: 0.1211\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 4.9301 - acc: 0.2021 - val_loss: 7.0495 - val_acc: 0.1214\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.7870 - acc: 0.2139 - val_loss: 7.1159 - val_acc: 0.1210\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.6505 - acc: 0.2244 - val_loss: 7.2013 - val_acc: 0.1201\n",
      "Best validation acc of epoch: 0.12137505773068155\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 130us/step - loss: 7.4718 - acc: 0.0368 - val_loss: 7.4830 - val_acc: 0.0469\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8532 - acc: 0.0571 - val_loss: 7.1769 - val_acc: 0.0737\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.4092 - acc: 0.0959 - val_loss: 6.9531 - val_acc: 0.0966\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.0542 - acc: 0.1230 - val_loss: 6.8382 - val_acc: 0.1082\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.7709 - acc: 0.1426 - val_loss: 6.7747 - val_acc: 0.1164\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.5293 - acc: 0.1581 - val_loss: 6.7826 - val_acc: 0.1197\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.3206 - acc: 0.1707 - val_loss: 6.7967 - val_acc: 0.1231\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1338 - acc: 0.1820 - val_loss: 6.8464 - val_acc: 0.1264\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 4.9643 - acc: 0.1925 - val_loss: 6.8957 - val_acc: 0.1258\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 4.8111 - acc: 0.2030 - val_loss: 6.9788 - val_acc: 0.1295\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.6716 - acc: 0.2131 - val_loss: 7.0394 - val_acc: 0.1282\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.5488 - acc: 0.2228 - val_loss: 7.1223 - val_acc: 0.1291\n",
      "Best validation acc of epoch: 0.1294531368759999\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 132us/step - loss: 7.4561 - acc: 0.0373 - val_loss: 7.4684 - val_acc: 0.0470\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 6.8487 - acc: 0.0595 - val_loss: 7.1884 - val_acc: 0.0761\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 6.4188 - acc: 0.0952 - val_loss: 6.9798 - val_acc: 0.0934\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 43s 122us/step - loss: 6.0617 - acc: 0.1208 - val_loss: 6.8657 - val_acc: 0.1053\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.7734 - acc: 0.1404 - val_loss: 6.7902 - val_acc: 0.1150\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.5277 - acc: 0.1568 - val_loss: 6.7866 - val_acc: 0.1202\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.3133 - acc: 0.1711 - val_loss: 6.7858 - val_acc: 0.1257\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.1185 - acc: 0.1829 - val_loss: 6.8432 - val_acc: 0.1274\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.9434 - acc: 0.1943 - val_loss: 6.8865 - val_acc: 0.1303\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 4.7868 - acc: 0.2042 - val_loss: 6.9706 - val_acc: 0.1287\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 4.6474 - acc: 0.2146 - val_loss: 7.0399 - val_acc: 0.1282\n",
      "Best validation acc of epoch: 0.13031955564427913\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 129us/step - loss: 7.5685 - acc: 0.0378 - val_loss: 7.5597 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1329 - acc: 0.0417 - val_loss: 7.4451 - val_acc: 0.0503\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.9741 - acc: 0.0505 - val_loss: 7.3704 - val_acc: 0.0554\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8254 - acc: 0.0604 - val_loss: 7.2810 - val_acc: 0.0638\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.6829 - acc: 0.0686 - val_loss: 7.2024 - val_acc: 0.0700\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.5664 - acc: 0.0748 - val_loss: 7.1541 - val_acc: 0.0721\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.4637 - acc: 0.0806 - val_loss: 7.1122 - val_acc: 0.0768\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.3718 - acc: 0.0856 - val_loss: 7.0827 - val_acc: 0.0778\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2926 - acc: 0.0894 - val_loss: 7.0568 - val_acc: 0.0813\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2196 - acc: 0.0934 - val_loss: 7.0312 - val_acc: 0.0837\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.1521 - acc: 0.0968 - val_loss: 7.0186 - val_acc: 0.0845\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0898 - acc: 0.1000 - val_loss: 7.0017 - val_acc: 0.0862\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0332 - acc: 0.1032 - val_loss: 7.0190 - val_acc: 0.0886\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.9772 - acc: 0.1062 - val_loss: 6.9917 - val_acc: 0.0928\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 43s 121us/step - loss: 5.9297 - acc: 0.1083 - val_loss: 7.0041 - val_acc: 0.0933\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8873 - acc: 0.1102 - val_loss: 6.9966 - val_acc: 0.0944\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8481 - acc: 0.1124 - val_loss: 7.0011 - val_acc: 0.0946\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8128 - acc: 0.1138 - val_loss: 7.0044 - val_acc: 0.0953\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7816 - acc: 0.1153 - val_loss: 7.0089 - val_acc: 0.0957\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7511 - acc: 0.1171 - val_loss: 7.0210 - val_acc: 0.0971\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7234 - acc: 0.1189 - val_loss: 7.0150 - val_acc: 0.0974\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6966 - acc: 0.1193 - val_loss: 7.0378 - val_acc: 0.0986\n",
      "Epoch 23/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6734 - acc: 0.1206 - val_loss: 7.0277 - val_acc: 0.0986\n",
      "Epoch 24/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6503 - acc: 0.1215 - val_loss: 7.0510 - val_acc: 0.0981\n",
      "Best validation acc of epoch: 0.09861882670724266\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 131us/step - loss: 7.4571 - acc: 0.0385 - val_loss: 7.4933 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 6.8503 - acc: 0.0578 - val_loss: 7.1511 - val_acc: 0.0742\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.3586 - acc: 0.1021 - val_loss: 6.9236 - val_acc: 0.0996\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.9917 - acc: 0.1282 - val_loss: 6.8216 - val_acc: 0.1116\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.6951 - acc: 0.1494 - val_loss: 6.7724 - val_acc: 0.1189\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.4407 - acc: 0.1648 - val_loss: 6.7780 - val_acc: 0.1235\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.2220 - acc: 0.1777 - val_loss: 6.8176 - val_acc: 0.1260\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.0208 - acc: 0.1907 - val_loss: 6.8762 - val_acc: 0.1259\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.8386 - acc: 0.2024 - val_loss: 6.9499 - val_acc: 0.1280\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.6785 - acc: 0.2136 - val_loss: 7.0180 - val_acc: 0.1265\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 4.5293 - acc: 0.2254 - val_loss: 7.1006 - val_acc: 0.1271\n",
      "Best validation acc of epoch: 0.12797512836360547\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 134us/step - loss: 8.4274 - acc: 0.0284 - val_loss: 7.6124 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 42s 119us/step - loss: 7.8163 - acc: 0.0389 - val_loss: 7.5730 - val_acc: 0.0469\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.5698 - acc: 0.0429 - val_loss: 7.5362 - val_acc: 0.0466\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.3886 - acc: 0.0440 - val_loss: 7.5089 - val_acc: 0.0443\n",
      "Best validation acc of epoch: 0.046939503678527124\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 130us/step - loss: 7.5133 - acc: 0.0379 - val_loss: 7.5402 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1176 - acc: 0.0421 - val_loss: 7.4285 - val_acc: 0.0463\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.9008 - acc: 0.0550 - val_loss: 7.3073 - val_acc: 0.0610\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.6584 - acc: 0.0717 - val_loss: 7.1614 - val_acc: 0.0699\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.4295 - acc: 0.0857 - val_loss: 7.0817 - val_acc: 0.0752\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2272 - acc: 0.0962 - val_loss: 7.0250 - val_acc: 0.0828\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0444 - acc: 0.1055 - val_loss: 7.0128 - val_acc: 0.0905\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8877 - acc: 0.1135 - val_loss: 7.0032 - val_acc: 0.0932\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7515 - acc: 0.1199 - val_loss: 7.0038 - val_acc: 0.0959\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6399 - acc: 0.1246 - val_loss: 7.0131 - val_acc: 0.0982\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.5419 - acc: 0.1285 - val_loss: 7.0485 - val_acc: 0.0992\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4595 - acc: 0.1334 - val_loss: 7.0627 - val_acc: 0.1009\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3857 - acc: 0.1371 - val_loss: 7.0801 - val_acc: 0.1028\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3190 - acc: 0.1411 - val_loss: 7.1150 - val_acc: 0.1020\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.2599 - acc: 0.1450 - val_loss: 7.1090 - val_acc: 0.1041\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.2100 - acc: 0.1487 - val_loss: 7.1285 - val_acc: 0.1041\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1641 - acc: 0.1522 - val_loss: 7.1360 - val_acc: 0.1055\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1198 - acc: 0.1557 - val_loss: 7.1551 - val_acc: 0.1058\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.0804 - acc: 0.1581 - val_loss: 7.1581 - val_acc: 0.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 5.0439 - acc: 0.1616 - val_loss: 7.1871 - val_acc: 0.1052\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.0104 - acc: 0.1640 - val_loss: 7.1870 - val_acc: 0.1063\n",
      "Best validation acc of epoch: 0.10641659424107627\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 131us/step - loss: 7.5202 - acc: 0.0390 - val_loss: 7.5086 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.0539 - acc: 0.0467 - val_loss: 7.3630 - val_acc: 0.0565\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.7649 - acc: 0.0701 - val_loss: 7.1428 - val_acc: 0.0817\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.5096 - acc: 0.0915 - val_loss: 7.0271 - val_acc: 0.0904\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.3219 - acc: 0.1041 - val_loss: 6.9619 - val_acc: 0.0975\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.1748 - acc: 0.1131 - val_loss: 6.8894 - val_acc: 0.1033\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0469 - acc: 0.1204 - val_loss: 6.8655 - val_acc: 0.1051\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.9394 - acc: 0.1262 - val_loss: 6.8565 - val_acc: 0.1080\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8459 - acc: 0.1321 - val_loss: 6.8475 - val_acc: 0.1116\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7584 - acc: 0.1372 - val_loss: 6.8737 - val_acc: 0.1133\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6865 - acc: 0.1413 - val_loss: 6.8631 - val_acc: 0.1151\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.6128 - acc: 0.1447 - val_loss: 6.9272 - val_acc: 0.1150\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.5527 - acc: 0.1488 - val_loss: 6.9194 - val_acc: 0.1160\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4971 - acc: 0.1515 - val_loss: 6.9553 - val_acc: 0.1159\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.4428 - acc: 0.1545 - val_loss: 6.9721 - val_acc: 0.1150\n",
      "Best validation acc of epoch: 0.1159981653549202\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 132us/step - loss: 7.5173 - acc: 0.0367 - val_loss: 7.4957 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.0440 - acc: 0.0471 - val_loss: 7.4351 - val_acc: 0.0504\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8634 - acc: 0.0569 - val_loss: 7.2696 - val_acc: 0.0688\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.6490 - acc: 0.0769 - val_loss: 7.1549 - val_acc: 0.0762\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 6.4818 - acc: 0.0881 - val_loss: 7.0679 - val_acc: 0.0831\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 6.3574 - acc: 0.0967 - val_loss: 7.0091 - val_acc: 0.0895\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2576 - acc: 0.1027 - val_loss: 6.9825 - val_acc: 0.0934\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.1738 - acc: 0.1069 - val_loss: 6.9519 - val_acc: 0.0969\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.1074 - acc: 0.1115 - val_loss: 6.9358 - val_acc: 0.0986\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0489 - acc: 0.1148 - val_loss: 6.9337 - val_acc: 0.1002\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.0002 - acc: 0.1176 - val_loss: 6.9307 - val_acc: 0.1013\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.9563 - acc: 0.1200 - val_loss: 6.9315 - val_acc: 0.1030\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.9194 - acc: 0.1220 - val_loss: 6.9413 - val_acc: 0.1039\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8871 - acc: 0.1237 - val_loss: 6.9407 - val_acc: 0.1037\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8576 - acc: 0.1260 - val_loss: 6.9492 - val_acc: 0.1036\n",
      "Best validation acc of epoch: 0.10391927039451321\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 46s 131us/step - loss: 7.5231 - acc: 0.0369 - val_loss: 7.5573 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1301 - acc: 0.0414 - val_loss: 7.4990 - val_acc: 0.0429\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.9536 - acc: 0.0515 - val_loss: 7.3384 - val_acc: 0.0582\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.7363 - acc: 0.0677 - val_loss: 7.2096 - val_acc: 0.0674\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.5373 - acc: 0.0796 - val_loss: 7.1388 - val_acc: 0.0737\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.3638 - acc: 0.0892 - val_loss: 7.0595 - val_acc: 0.0798\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.2070 - acc: 0.0977 - val_loss: 7.0148 - val_acc: 0.0844\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.0725 - acc: 0.1045 - val_loss: 7.0009 - val_acc: 0.0906\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.9570 - acc: 0.1103 - val_loss: 6.9786 - val_acc: 0.0938\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.8567 - acc: 0.1153 - val_loss: 6.9746 - val_acc: 0.0968\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.7697 - acc: 0.1194 - val_loss: 6.9900 - val_acc: 0.0976\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 5.6916 - acc: 0.1229 - val_loss: 6.9889 - val_acc: 0.0998\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 42s 118us/step - loss: 5.6213 - acc: 0.1262 - val_loss: 7.0062 - val_acc: 0.1023\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.5624 - acc: 0.1287 - val_loss: 7.0226 - val_acc: 0.1019\n",
      "Epoch 15/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.5102 - acc: 0.1307 - val_loss: 7.0271 - val_acc: 0.1029\n",
      "Epoch 16/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 5.4615 - acc: 0.1332 - val_loss: 7.0526 - val_acc: 0.1043\n",
      "Epoch 17/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.4161 - acc: 0.1360 - val_loss: 7.0522 - val_acc: 0.1034\n",
      "Epoch 18/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 5.3741 - acc: 0.1380 - val_loss: 7.0634 - val_acc: 0.1046\n",
      "Epoch 19/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.3376 - acc: 0.1398 - val_loss: 7.0777 - val_acc: 0.1054\n",
      "Epoch 20/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.3047 - acc: 0.1416 - val_loss: 7.0943 - val_acc: 0.1047\n",
      "Epoch 21/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.2714 - acc: 0.1448 - val_loss: 7.1058 - val_acc: 0.1064\n",
      "Epoch 22/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 5.2404 - acc: 0.1463 - val_loss: 7.1364 - val_acc: 0.1067\n",
      "Epoch 23/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.2138 - acc: 0.1475 - val_loss: 7.1218 - val_acc: 0.1061\n",
      "Epoch 24/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1904 - acc: 0.1496 - val_loss: 7.1465 - val_acc: 0.1075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 5.1664 - acc: 0.1515 - val_loss: 7.1566 - val_acc: 0.1067\n",
      "Epoch 26/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 5.1425 - acc: 0.1533 - val_loss: 7.1759 - val_acc: 0.1069\n",
      "Best validation acc of epoch: 0.107486875946779\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 132us/step - loss: 7.8273 - acc: 0.0319 - val_loss: 7.5271 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.3569 - acc: 0.0429 - val_loss: 7.5324 - val_acc: 0.0447\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.2533 - acc: 0.0455 - val_loss: 7.5503 - val_acc: 0.0468\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1756 - acc: 0.0471 - val_loss: 7.5260 - val_acc: 0.0478\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1139 - acc: 0.0480 - val_loss: 7.5359 - val_acc: 0.0489\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 7.0637 - acc: 0.0489 - val_loss: 7.5307 - val_acc: 0.0473\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.0202 - acc: 0.0499 - val_loss: 7.5485 - val_acc: 0.0504\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 6.9892 - acc: 0.0509 - val_loss: 7.5347 - val_acc: 0.0512\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 41s 117us/step - loss: 6.9569 - acc: 0.0520 - val_loss: 7.5451 - val_acc: 0.0508\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 6.9324 - acc: 0.0528 - val_loss: 7.5430 - val_acc: 0.0529\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.9090 - acc: 0.0535 - val_loss: 7.5634 - val_acc: 0.0509\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8876 - acc: 0.0543 - val_loss: 7.5471 - val_acc: 0.0527\n",
      "Best validation acc of epoch: 0.05285153670569582\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 133us/step - loss: 15.6896 - acc: 0.0079 - val_loss: 15.6415 - val_acc: 0.0084\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 14.3955 - acc: 0.0094 - val_loss: 7.7124 - val_acc: 0.0264\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 115us/step - loss: 7.2026 - acc: 0.0356 - val_loss: 7.5719 - val_acc: 0.0424\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1348 - acc: 0.0411 - val_loss: 7.5840 - val_acc: 0.0424\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1228 - acc: 0.0411 - val_loss: 7.5960 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 74s 210us/step - loss: 8.4576 - acc: 0.0265 - val_loss: 7.6170 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1856 - acc: 0.0411 - val_loss: 7.5890 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 7.1581 - acc: 0.0411 - val_loss: 7.6033 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 132us/step - loss: 7.6587 - acc: 0.0347 - val_loss: 7.5335 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 7.2433 - acc: 0.0411 - val_loss: 7.5719 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 7.2044 - acc: 0.0419 - val_loss: 7.5123 - val_acc: 0.0431\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 7.1377 - acc: 0.0454 - val_loss: 7.4706 - val_acc: 0.0469\n",
      "Epoch 5/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 7.0663 - acc: 0.0477 - val_loss: 7.4228 - val_acc: 0.0471\n",
      "Epoch 6/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.0082 - acc: 0.0508 - val_loss: 7.3769 - val_acc: 0.0505\n",
      "Epoch 7/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.9496 - acc: 0.0555 - val_loss: 7.3375 - val_acc: 0.0552\n",
      "Epoch 8/50\n",
      "353176/353176 [==============================] - 40s 114us/step - loss: 6.8887 - acc: 0.0609 - val_loss: 7.2860 - val_acc: 0.0626\n",
      "Epoch 9/50\n",
      "353176/353176 [==============================] - 42s 120us/step - loss: 6.8335 - acc: 0.0646 - val_loss: 7.2553 - val_acc: 0.0650\n",
      "Epoch 10/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.7854 - acc: 0.0679 - val_loss: 7.2225 - val_acc: 0.0689\n",
      "Epoch 11/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.7446 - acc: 0.0703 - val_loss: 7.2042 - val_acc: 0.0694\n",
      "Epoch 12/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.7106 - acc: 0.0718 - val_loss: 7.1777 - val_acc: 0.0730\n",
      "Epoch 13/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.6799 - acc: 0.0740 - val_loss: 7.1690 - val_acc: 0.0723\n",
      "Epoch 14/50\n",
      "353176/353176 [==============================] - 40s 113us/step - loss: 6.6478 - acc: 0.0755 - val_loss: 7.1574 - val_acc: 0.0729\n",
      "Best validation acc of epoch: 0.07295754526407977\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 49s 137us/step - loss: 7.9603 - acc: 0.0159 - val_loss: 7.5106 - val_acc: 0.0265\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1302 - acc: 0.0403 - val_loss: 7.5232 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1180 - acc: 0.0411 - val_loss: 7.5353 - val_acc: 0.0424\n",
      "Epoch 4/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.1131 - acc: 0.0411 - val_loss: 7.5442 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 47s 132us/step - loss: 8.6202 - acc: 0.0249 - val_loss: 7.6589 - val_acc: 0.0424\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.3508 - acc: 0.0411 - val_loss: 7.6057 - val_acc: 0.0424\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 40s 112us/step - loss: 7.2743 - acc: 0.0411 - val_loss: 7.5685 - val_acc: 0.0424\n",
      "Best validation acc of epoch: 0.04242903013009221\n",
      "Train on 353176 samples, validate on 39242 samples\n",
      "Epoch 1/50\n",
      "353176/353176 [==============================] - 49s 138us/step - loss: 7.5563 - acc: 0.0326 - val_loss: 15.8298 - val_acc: 0.0179\n",
      "Epoch 2/50\n",
      "353176/353176 [==============================] - 41s 116us/step - loss: 7.2019 - acc: 0.0409 - val_loss: 15.8297 - val_acc: 0.0179\n",
      "Epoch 3/50\n",
      "353176/353176 [==============================] - 41s 115us/step - loss: 7.1942 - acc: 0.0410 - val_loss: 15.8297 - val_acc: 0.0179\n",
      "Best validation acc of epoch: 0.017863513596863227\n",
      "Evalutation of best performing model:\n",
      "39242/39242 [==============================] - 16s 396us/step\n",
      "[7.039917215575052, 0.12820447479741093]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 1, 'Dense_1': 0, 'Dropout': 0.1461812347504796, 'Dropout_1': 0, 'Dropout_2': 0.9982632206283798, 'Dropout_3': 0, 'decay': 0, 'decay_1': 1, 'decay_2': 0, 'lr': 1, 'lstm_size': 1, 'lstm_size_1': 0, 'trainable': 1}\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='text-gen-lstm-hyperas-2')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "def reweight_word(preds, word_dict_len, temperature):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    preds = preds.reshape(word_dict_len)\n",
    "    probas = np.random.multinomial(1, preds, 1)[0]\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def create_text(model_path, lookup_path, training_length, num_output_words=20, temperature=0.5):\n",
    "    output_words = []\n",
    "    input_words = [[]]\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    with open(lookup_path, 'r') as file:\n",
    "        reverse_lookup = json.loads(file.read())\n",
    "        \n",
    "    word_dict_len = len(reverse_lookup) + 1\n",
    "\n",
    "    for x in range(training_length):\n",
    "        input_words[0].append(random.randint(0,word_dict_len - 1))\n",
    "        \n",
    "    input_words = np.asarray(input_words)\n",
    "\n",
    "    for i in range(num_output_words):\n",
    "        word_oh = model.predict(input_words)\n",
    "        weighted_index = reweight_word(word_oh, word_dict_len, temperature)\n",
    "        word = reverse_lookup[str(np.argmax(word_oh))]\n",
    "        output_words.append(word)\n",
    "    \n",
    "        new_input_placeholder = [[]]\n",
    "        for i in range(training_length):\n",
    "            index = i + 1\n",
    "            if i < 2:\n",
    "                new_input_placeholder[0].append(input_words[0][index])\n",
    "            else:\n",
    "                new_input_placeholder[0].append(weighted_index)\n",
    "    \n",
    "        input_words = np.asarray(new_input_placeholder)\n",
    "    \n",
    "    output_tweet = ' '.join(output_words)\n",
    "    \n",
    "    return output_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Temperature: 0.1\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: to the election s is a great guy to be the u and the great of the of the fbi\n",
      "2: is be a great governor of the great state of ohio and a great disaster for the u s is\n",
      "3: on record high crime and many more years of the u s is a great guy who is a total\n",
      "====================\n",
      "Temperature: 0.25\n",
      "====================\n",
      "1: is a total disaster for the u s is the fbi is a best thing the people is a great\n",
      "2: to the new york times is a total guy who is a a plateau it's a beginning to be a\n",
      "3: year killing in the u s is a great guy to be in the u s is a great guy\n",
      "====================\n",
      "Temperature: 0.5\n",
      "====================\n",
      "1: of the great state of ohio is will be interviewed by foxandfriends tonight seanhannity trump discussing the tweets erictrump is\n",
      "2: to be in the u of a total in the history and doj and the are a great to make\n",
      "3: the is a a plateau it's a beginning to is have been a total meltdown on the solution york times\n",
      "====================\n",
      "Temperature: 0.75\n",
      "====================\n",
      "1: of the trump to be been been a to the of the money penalty for the great and smart and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: in the u of on the country and are be let a better than the u of the country and\n",
      "3: i the the world is be a tax cuts and in the into our country and great honor to the\n",
      "====================\n",
      "Temperature: 0.95\n",
      "====================\n",
      "1: of great job people in the white of the they to will #trump2016 #makeamericagreatagain omaha missusa of staff the the\n",
      "2: is restaurant exclusively amp shirts are be to america great again rally in can seen the on the to for\n",
      "3: in god not of the the the we the u will a happy the news is the palestinian of the\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.1, 0.25, 0.5, 0.75, 0.95]:\n",
    "    print('====================')\n",
    "    print(f'Temperature: {temp}')\n",
    "    print('====================')\n",
    "    for i in range(3):\n",
    "        tweet = create_text('model3.h5', 'trump_word_dict_reverse2.json', 3,\n",
    "                        num_output_words=20, temperature=temp)\n",
    "        print(f'{i + 1}: {tweet}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
